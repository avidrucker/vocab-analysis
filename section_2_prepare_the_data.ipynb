{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab Analysis \n",
    "## Section 2: Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime, timedelta, date\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"datasets/collection.anki2\"\n",
    "cnx = sqlite3.connect(location) # create sql file connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDD backbone assertion to confirm a function call returns the desired result\n",
    "def assertEquals(actual, expected, desc):\n",
    "    assert(actual==expected), desc + \" result: \" + str(actual) + \", expected: \" + str(expected)\n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word anout how the data was stored\n",
    "\n",
    "Anki, the Open Source, Spaced Repetition software (& app & service), saves a student's data in a few locations. There are the \"Notes\" which are the raw info used to make cards (fields of vocab data, metatags, trivia facts, images, audio, etc..) Then there are the \"Cards\" which are the actual studied items, where the study overview data is stored (such as study date-times, repetitions (reviews), intervals (how long a card is to be remembered), lapses (forgets & subsequent interval resets)). Additionally, data concerning the entire collection is stored under something cryptically called \"Columns\". Lastly, there is a \"RevLog\" which contains all the study data in detail for each individual repetition (study datetime, card studied, etc..) This document was critical to piecing together the puzzle: https://github.com/ankidroid/Anki-Android/wiki/Database-Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract Deck Creation Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-08 09:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c = pd.read_sql_query(\"SELECT * FROM col\", cnx)\n",
    "crt = df_c['crt'][0] # save collection creation date (in epoch time)\n",
    "pd_crt = pd.to_datetime(crt, unit = 's')\n",
    "print(pd_crt)\n",
    "\n",
    "assertEquals(str(pd_crt), \"2013-01-08 09:00:00\", \"Collection Creation Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract field names to label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = []\n",
    "for row_index, blob in df_c['models'].items():\n",
    "    for model_id, data in json.loads(blob).items():\n",
    "        field_names += list(map(lambda fld: fld['name'], data['flds']))\n",
    "field_names.append('Tags')\n",
    "expected_names = ['Term', 'Yomi1', 'Translation', 'Translation2', 'Translation3', 'AlternateForms', 'PartOfSpeech', 'Sound', 'Sound2', 'Sound3', 'Examples', 'ExamplesAudio', 'AtoQ', 'AtoQaudio', 'AtoQkana', 'AtoQtranslation', 'QandApicture', 'answerPicture', 'Meaning1', 'SimilarWords', 'RelatedWords', 'Breakdown1', 'Comparison', 'Usage', 'Prompt1', 'Prompt2', 'KakuMCD', 'IuMCD', 'ExtraMemo', 'Yomi2', 'Meaning2', 'Breakdown2', 'Picture1', 'Picture2', 'Picture3', 'Picture4', 'HinshiMarker', 'Hint', 'Term2', 'ArabicNumeral', 'CounterKanji', 'Mnemonic', 'SameSoundWords', 'Yomi3', 'gChap', 'gBook', 'semester', 'gNumber', 'Transliteration', 'SoloLookCards', 'TagOverflow', 'blank1', 'blank2', 'Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(field_names, expected_names, \"Field Names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Import card study data into data frame \"df_cards\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Take in study data from Anki collection\n",
    "df_cards = pd.read_sql_query(\"SELECT * FROM cards\", cnx)\n",
    "assertEquals(df_cards.shape[0],19315,\"Rows\")#6386, 21979, 19363\n",
    "assertEquals(df_cards.shape[1],18,\"Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Confirm that card data model matches expected format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_columns_1 = ['id', 'nid', 'did', 'ord', 'mod', 'usn', 'type', 'queue', 'due', 'ivl', 'factor',\n",
    " 'reps', 'lapses', 'left', 'odue', 'odid', 'flags', 'data']\n",
    "\n",
    "def lists_equal(a,b):\n",
    "    return (a == b).all()\n",
    "\n",
    "assertEquals(lists_equal(df_cards.columns.values, expected_columns_1), True, \"Card Columns Import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Shallow check for duplicates (matching rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    " def has_dupes(df_in):\n",
    "    dupe = df_in.duplicated()\n",
    "    return df_in.loc[dupe].shape[0] != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(has_dupes(df_cards), False, \"Duplicates Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Remove unneeded card dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_line_break():\n",
    "    print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_before_after(b, a, t=\"\"):\n",
    "    if t != \"\":\n",
    "        print_line_break()\n",
    "        print(t)\n",
    "    print_line_break()\n",
    "    print(\"Before: \" + str(b))\n",
    "    print_line_break()\n",
    "    print(\"After: \" + str(a))\n",
    "    print_line_break()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Card Columns:\n",
      "---------------------------------------------------------------------------\n",
      "Before: ['id' 'nid' 'did' 'ord' 'mod' 'usn' 'type' 'queue' 'due' 'ivl' 'factor'\n",
      " 'reps' 'lapses' 'left' 'odue' 'odid' 'flags' 'data']\n",
      "---------------------------------------------------------------------------\n",
      "After: ['id' 'nid' 'ord' 'queue' 'due' 'ivl' 'factor' 'reps' 'lapses']\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cards_001_less_cols = df_cards.copy()\n",
    "df_cards_001_less_cols = df_cards_001_less_cols.drop(['did','usn','type','mod','left','odue','odid','flags','data'],axis=1)\n",
    "expected_columns_2 = ['id', 'nid', 'ord', 'queue', 'due', 'ivl', 'factor', 'reps','lapses']\n",
    "\n",
    "print_before_after(df_cards.columns.values, df_cards_001_less_cols.columns.values,\"Card Columns:\")\n",
    "\n",
    "assertEquals(lists_equal(df_cards_001_less_cols.columns.values, expected_columns_2), True, \"Card Model Slimmed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Import notes (words) into data frame \"df_notes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take in the 'notes' table, and explicitly save the note id (\"nid\") \n",
    "df_notes = pd.read_sql_query(\"SELECT * FROM notes\", cnx)\n",
    "df_notes = df_notes.rename(columns={'id':'nid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(df_notes.shape[0],8384,\"Rows\") # 2791, 9784, 8403\n",
    "assertEquals(df_notes.shape[1],11,\"Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Remove (drop) unneeded fields (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Before: ['nid' 'guid' 'mid' 'mod' 'usn' 'tags' 'flds' 'sfld' 'csum' 'flags' 'data']\n",
      "---------------------------------------------------------------------------\n",
      "After: ['nid' 'mod' 'tags' 'flds']\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_notes_old_col_vals = df_notes.columns.values\n",
    "df_notes = df_notes.drop(['guid','mid','usn','sfld','csum','flags','data'],axis=1)\n",
    "#print(df_notes.columns.values)\n",
    "print_before_after(df_notes_old_col_vals, df_notes.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Split \"fields\" column into multiple, assign field names, drop combined col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func, *args, **kwargs):\n",
    "    start = time.time()\n",
    "    func(*args, **kwargs)\n",
    "    end = time.time()\n",
    "    # https://stackoverflow.com/questions/8885663/how-to-format-a-floating-number-to-fixed-width-in-python\n",
    "    print(\"{:.0f}\".format((end - start)*1000) + \" miliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nid' 'mod' 'tags' 'Term' 'Yomi1' 'Translation' 'Translation2'\n",
      " 'Translation3' 'AlternateForms' 'PartOfSpeech' 'Sound' 'Sound2' 'Sound3'\n",
      " 'Examples' 'ExamplesAudio' 'AtoQ' 'AtoQaudio' 'AtoQkana'\n",
      " 'AtoQtranslation' 'QandApicture' 'answerPicture' 'Meaning1'\n",
      " 'SimilarWords' 'RelatedWords' 'Breakdown1' 'Comparison' 'Usage' 'Prompt1'\n",
      " 'Prompt2' 'KakuMCD' 'IuMCD' 'ExtraMemo' 'Yomi2' 'Meaning2' 'Breakdown2'\n",
      " 'Picture1' 'Picture2' 'Picture3' 'Picture4' 'HinshiMarker' 'Hint' 'Term2'\n",
      " 'ArabicNumeral' 'CounterKanji' 'Mnemonic' 'SameSoundWords' 'Yomi3'\n",
      " 'gChap' 'gBook' 'semester' 'gNumber' 'Transliteration' 'SoloLookCards'\n",
      " 'TagOverflow' 'blank1' 'blank2']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(expected_names)-1):\n",
    "    df_notes[expected_names[i]] = df_notes.flds.str.split('\u001f').str.get(i)\n",
    "assertEquals('flds' in df_notes.columns.values, True, \"'flds' Column Found\")\n",
    "df_notes = df_notes.drop(['flds'],axis=1)\n",
    "assertEquals('flds' not in df_notes.columns.values, True, \"'flds' Column Not Found\")\n",
    "print(df_notes.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Check notes for duplicates (shallow check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(has_dupes(df_notes), False, \"Duplicates Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Check for duplicates by term field in notes data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_dupe_terms(df_in):\n",
    "    location = df_in['Term'].duplicated()\n",
    "    return df_in.loc[location].shape[0] != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(has_dupe_terms(df_notes), False, \"Duplicates Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Confirm that duplicates dataframe is empty (no dups exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 56)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe = df_notes['Term'].duplicated() #creates list of True/False values\n",
    "print(df_notes[dupe].shape)\n",
    "assertEquals(df_notes[dupe].shape[0], 0, \"Duplicates dataframe is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Inspect an individual card by its term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postal service\n",
    "def inspect_note(df_in, term):\n",
    "    return df_in[df_in['Term']==term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>Yomi3</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>1361674609381</td>\n",
       "      <td>1555887839</td>\n",
       "      <td>Japanese Marked abaCheckNuance addDefinition ...</td>\n",
       "      <td>郵便</td>\n",
       "      <td>ゆうびん</td>\n",
       "      <td>mail, postal service</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>〒</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid         mod  \\\n",
       "3282  1361674609381  1555887839   \n",
       "\n",
       "                                                   tags Term Yomi1  \\\n",
       "3282   Japanese Marked abaCheckNuance addDefinition ...   郵便  ゆうびん   \n",
       "\n",
       "               Translation Translation2 Translation3 AlternateForms  \\\n",
       "3282  mail, postal service                                        〒   \n",
       "\n",
       "           PartOfSpeech  ...   Yomi3 gChap gBook semester gNumber  \\\n",
       "3282  Common word, Noun  ...                                        \n",
       "\n",
       "     Transliteration SoloLookCards TagOverflow blank1 blank2  \n",
       "3282                                                          \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel1 = inspect_note(df_notes,'郵便')\n",
    "sel1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Point, Commit, Bonfire (for you Souls fans)*\n",
    "\n",
    "At the point in time of the data extraction where the (meta) tag information is made available, we can treat it to both clarify (rename poorly worded tags) & reduce (delete unneeded tags). Since we now have all fields split into their own columns as well, we can treat (modifiy & improve) the columns as well, in a 1-2 process: (1) Fix the tags & (2) Fix the columns\n",
    "*https://en.wikipedia.org/wiki/Souls_(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_list(takeIn, takeOut):\n",
    "    temp = takeIn.lower().split() # split all the words into a list\n",
    "    temp2 = [word for word in temp if word.lower() not in takeOut] # create a shorter list of words minus the take-outs\n",
    "    return ' '.join(temp2) # return that shorter list as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_remove_list = ['japanese', 'checkpicture', 'complete', 'haspicture', 'nomemo',\n",
    "                   'researched', 'aaaeditthis', 'addaudio', 'addaudio2', 'addaudioNow',\n",
    "                   'addmore','adjustformatting', 'hascomparison', 'hasmnemonic',\n",
    "                   'customediting','wikidefinition', 'givewill','addaudionow','addprompt',\n",
    "                   'checknuance','giveyaneury','hastextimage', 'marked', 'addpicture',\n",
    "                   'addexampletranslation','basicnumeric', 'genkiplus', 'hasaudio',\n",
    "                   'nativeaudio', 'adddefinition','addexamples', 'addjapaneseprompt',\n",
    "                   'computervoice','haspoliteprefix','nongoo','customdefinition','hashint',\n",
    "                   'abahipriorityfix','kaki','mcd','nobodyknows+','missingwordtype',\n",
    "                   'image','duplicate', 'hasprompt', 'ninshiki','abachecknuance',\n",
    "                   'hasflag','things', 'jim', 'hasunicode', 'editthis','aaahipriority',\n",
    "                   'hassimpledef', 'givecodie', 'forjimmy', 'hasnativeaudio', 'givejimmy2',\n",
    "                   'checkaudio', 'checkwriting', 'hasjlptlevel', 'makekaki', 'checknuance2',\n",
    "                   'checkagain', 'newaudio', 'mail', 'checkexamples','elementaryschool',\n",
    "                   'nvc', 'checkprompt', 'gavejimmy', 'addnativeaudio','checkreading',\n",
    "                   'givecodieapril', 'activated', 'fixformatting','hasplacesuffix',\n",
    "                   'hassuffix','addtranslation','addnewcardtype','addnuance','addtextimage',\n",
    "                   'semicomplete', 'removeroboaudio','fixaudio','hasgramconj', \n",
    "                   'hasquestion', 'addkanji','changenotetype', 'famous', 'challenging',\n",
    "                   'kuverb', 'givwill','karutapoems', 'map', 'hasvisualcomparison',\n",
    "                   'picturekaki', 'jyugemu', '2018', 'type1', 'hasslang', 'apologies',\n",
    "                   'month', 'definitionresearched','soundshift', 'basics1', 'tsuverb',\n",
    "                   'facebook', 'uverb', 'checkfrequency', 'degree', 'hasdefinition',\n",
    "                   'addtransliteration', 'dnd', 'introductions', 'adjustprompt',\n",
    "                   'job', 'particle', 'services', 'mature', 'splitpictures', \n",
    "                   'egaki', 'type5k', 'intimate','extrainfo', 'irregular', 'unlisted',\n",
    "                   'fromwiki', 'checkdifference','addpronunciationdiagram', 'reset',\n",
    "                   'currentevents', 'doubletextimage', 'comparison', 'verbscompoundpast2',\n",
    "                   'attention', 'addmemo', 'averb', 'radio','hasascii', 'fontadjusted',\n",
    "                   'haspronunciation', 'borroweddefinition','alphabet', 'graphics',\n",
    "                   'chiebukuro', 'duolingo', 'ateji', 'fact','type5s', 'fixpicture',\n",
    "                   'politebydefault', 'objects','sensitive', 'groupword', 'addmnemonic',\n",
    "                   'hasmore', 'quote', 'checkformatting','overlap', 'kotobankdef',\n",
    "                   'hasrudeness', 'changedeck', 'specialformatting','yoga',\n",
    "                   'hasjapaneseprompt', 'hasprefix','questionword', 'business', \n",
    "                   'postoffice', 'firstten', 'money', 'robotvoice2', 'ichidan', 'godan',\n",
    "                   'weather','count', 'nodefinition', 'muverb', 'addcomparisonchart', \n",
    "                   'ruverb', 'phone', 'conjugated','haddiv','vulgar','fromkaruta',\n",
    "                   'karutamanual', 'teform', 'qanda', '2019'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Remove unneeded tags (meta-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>Yomi3</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797110</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>Japanese Marked abaCheckNuance checkNuance co...</td>\n",
       "      <td>臨機応変</td>\n",
       "      <td>りんきおうへん</td>\n",
       "      <td>adapting oneself to the requirements of the mo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun, No-adjective</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>Japanese complete noMemo researched wwwjdic</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797113</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>Japanese Marked abaCheckNuance checkNuance co...</td>\n",
       "      <td>苦汁</td>\n",
       "      <td>にがり</td>\n",
       "      <td>bittern; concentrated solution of salts (esp. ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod  \\\n",
       "0  1331799797110  1511481489   \n",
       "1  1331799797112  1511481489   \n",
       "2  1331799797113  1511481489   \n",
       "\n",
       "                                                tags  Term    Yomi1  \\\n",
       "0   Japanese Marked abaCheckNuance checkNuance co...  臨機応変  りんきおうへん   \n",
       "1       Japanese complete noMemo researched wwwjdic     隙間      すきま   \n",
       "2   Japanese Marked abaCheckNuance checkNuance co...    苦汁      にがり   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "0  adapting oneself to the requirements of the mo...                \n",
       "1            <div>crevice; crack; gap; opening</div>                \n",
       "2  bittern; concentrated solution of salts (esp. ...                \n",
       "\n",
       "  Translation3 AlternateForms                  PartOfSpeech  ...   Yomi3  \\\n",
       "0                                        Noun, No-adjective  ...           \n",
       "1                              <div>Common word, Noun</div>  ...           \n",
       "2                                                      Noun  ...           \n",
       "\n",
       "  gChap gBook semester gNumber Transliteration SoloLookCards TagOverflow  \\\n",
       "0                                                                          \n",
       "1                                                                          \n",
       "2                                                                          \n",
       "\n",
       "  blank1 blank2  \n",
       "0                \n",
       "1                \n",
       "2                \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# survey a few notes to see example tag data\n",
    "df_notes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Tags for 臨機応変\n",
      "---------------------------------------------------------------------------\n",
      "Before:  Japanese Marked abaCheckNuance checkNuance complete noMemo researched wwwjdic yojijukugo \n",
      "---------------------------------------------------------------------------\n",
      "After: wwwjdic yojijukugo\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likely useful tags: katakana, Waseigo, Food, Phrases, casual, restaurant, travel, commonWord, noun, suruVerb\n",
    "\n",
    "df_notes_001_less_tags = df_notes.copy() #originally \"df_notes_less_tags\"\n",
    "df_notes_001_less_tags['tags'] = df_notes_001_less_tags['tags'].apply(lambda x: shorten_list(str(x), tag_remove_list))\n",
    "\n",
    "print_before_after(df_notes['tags'].iloc[0], df_notes_001_less_tags['tags'].iloc[0],\"Tags for \" + df_notes['Term'].iloc[0])\n",
    "\n",
    "assertEquals(\"Japanese\" in df_notes['tags'].iloc[0].split(), True, \"Contains Tag 'Japanese'\")\n",
    "assertEquals(\"Japanese\" in df_notes_001_less_tags['tags'].iloc[0].split(), False, \"Contains Tag 'Japanese'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 17. Rename useful tags (meta-data) that were poorly named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace list (formerly named 'tag_replace_list')\n",
    "tag_rename_dict = {\n",
    "    'aalowfrequency':'rare checked', 'aatechnical':'technical checked', 'aaanonkaiwa':'nonconvo checked',\n",
    "    'wwwjdic':'fromdict', 'expression':'phrases', 'numberonly':'number',\n",
    "    'grammarpoint':'grammar', 'jisho':'fromdict', 'pointingword':'directions',\n",
    "    'geometry':'math technical', 'genki':'textbook', 'jpn202':'college',\n",
    "    'jpn201':'college', 'jpn101':'college', 'jpn102':'college', 'kentei':'fromexam',\n",
    "    'proficiencytest':'fromexam', 'bodypart':'body', '5kyuu':'fromexam',\n",
    "    'linguisticreference':'technical', 'conversation':'convo',\n",
    "    'fromconvo':'convo', 'culturepoint':'culture', 'checkednuance':'checked',\n",
    "    'checkedpictures':'checked', 'checkednuance':'checked', 'medical':'technical',\n",
    "    'anatomy':'body', 'places':'place', 'animals':'animal',\n",
    "    'newspaperterm':'fromnewspaper', 'checkedreading':'checked',\n",
    "    'abbreviation':'abbr','firstsemester':'semester1','onecharacter':'len1',\n",
    "    'sentence':'phrase', 'verbs':'verb', 'convook':'checked convo','inuse':'checked',\n",
    "    'nuancechecked':'checked','insects':'animal insect','sightseeing':'travel',\n",
    "    'accessories':'clothing', 'grammarsuffix':'suffix', 'oceanlife':'animal ocean',\n",
    "    'science':'technical', 'written':'nonconvo', 'notrare':'checked',\n",
    "    'aajoke':'silly', 'intonationcompare':'hassimilar', 'ij':'textbook',\n",
    "    'goodcard':'inspect','aahilevel':'challenging inspect', 'ijvocab':'textbook',\n",
    "    'cliothing':'clothing','unused':'nonconvo rare checked',\n",
    "    'aaunused':'nonconvo rare checked', 'samesound':'hassame','animals':'animal',\n",
    "    'dictionary':'fromdict','usuallywritteninkana':'kana',\n",
    "    'abVeryRare':'rare checked', 'yojijukugo':'rare idiom', 'abcasual':'casual checked convo',\n",
    "    'literaryform':'nonconvo', 'onomatopoeiclike':'onomatopoeic','kenjo':'humble',\n",
    "    'colors':'color', 'forest':'nature','flower':'plant nature', 'aaok':'checked',\n",
    "    'questions': 'question', 'adverbs':'adverb','book2':'textbook',\n",
    "    'book1':'textbook','proficiencytest':'fromtest','animalscomplete':'animal',\n",
    "    'sonkei':'respectful','eating':'food','fruit':'food','neverused':'nonconvo rare',\n",
    "    'domainspecific':'technical','seaons':'season','seasons':'season',\n",
    "    'prefecture':'place','plantpart':'plant', \"hakataben\":\"dialect\", \"fish\":\"animal fish\",\n",
    "    \"transitive\":\"transitive verb\", \"intransitive\":\"intransitive verb\",\n",
    "    \"aaunecessary\":\"nonconvo checked\", \"vegetables\":\"vegetable food plant\",\n",
    "    \"counters\":\"counter\", \"senmonyougo\":\"technical\", \"countries\":\"country place\",\n",
    "    \"date\":\"datesandtime\", \"rarelyused\":\"rare\", \"aaakaiwa\":\"convo checked\", \"cool\":\"inspect\",\n",
    "    \"investigate\":\"inspect\"\n",
    "}\n",
    "\n",
    "#todo: investigate:\n",
    "#editformatting,  datesandtime, linguistics, reference, adult, adjustpicture, checkpronunciation, addhint, challenging, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_list(takeIn, replaceDict):\n",
    "    temp = takeIn.lower().split()\n",
    "    temp2 = []\n",
    "    for word in temp:\n",
    "        if word in replaceDict:\n",
    "            temp2.append(replaceDict.get(word)) # if the word exists in the dictionary, replace it\n",
    "        else:\n",
    "            temp2.append(word) # if the word doesnt't exist in the dictionary, leave it alone\n",
    "    return ' '.join(temp2) # return that shorter list as a string\n",
    "\n",
    "# inspect further:\n",
    "# multiwriting, multimeaning, multipicture, multiterm, multireading, mergeterms, checkpronunciation, customterm,\n",
    "# goodcard, personalized, silly, addjlptlevel, checkpronunciation, mergeterms, customterm, transportation vs travel\n",
    "\n",
    "# categorize: iadjective, naajective, verb, counter, commonword, suruverb, pronoun, question, phrases, kuverb, godan, ichidan, intransitive, transitive, noun, adverbialnoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Tags for 臨機応変\n",
      "---------------------------------------------------------------------------\n",
      "Before: wwwjdic yojijukugo\n",
      "---------------------------------------------------------------------------\n",
      "After: fromdict rare idiom\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_002_better_tags = df_notes_001_less_tags.copy() # originally \"df_notes_better_tags\"\n",
    "df_notes_002_better_tags['tags'] = df_notes_002_better_tags['tags'].apply(lambda x: replace_list(str(x), tag_rename_dict))\n",
    "\n",
    "print_before_after(df_notes_001_less_tags['tags'].iloc[0], df_notes_002_better_tags['tags'].iloc[0], \"Tags for \" + df_notes_002_better_tags['Term'].iloc[0])\n",
    "\n",
    "assertEquals(\"wwwjdic\" in df_notes_001_less_tags['tags'].iloc[0].split(), True, \"Contains Tag 'wwwjdic'\")\n",
    "assertEquals(\"wwwjdic\" in df_notes_002_better_tags['tags'].iloc[0].split(), False, \"Contains Tag 'wwwjdic'\")\n",
    "assertEquals(\"fromdict\" in df_notes_001_less_tags['tags'].iloc[0].split(), False, \"Contains Tag 'fromdict'\")\n",
    "assertEquals(\"fromdict\" in df_notes_002_better_tags['tags'].iloc[0].split(), True, \"Contains Tag 'fromdict'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       1621\n",
       "fromdict                                796\n",
       "fromtest textbook                       600\n",
       "textbook textbook                       453\n",
       "college textbook textbook               241\n",
       "verb                                    200\n",
       "fromdict verb                           144\n",
       "fromexam                                126\n",
       "len1                                    121\n",
       "hiragana college textbook textbook      107\n",
       "counter numeric                          97\n",
       "numeric                                  81\n",
       "addsimilar                               81\n",
       "fromdict media                           72\n",
       "college textbook semester1 textbook      71\n",
       "fromexam textbook                        65\n",
       "fromdict lyrics                          63\n",
       "convo                                    61\n",
       "n3 fromdict transitive verb verb         58\n",
       "college textbook textbook katakana       54\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_002_better_tags['tags'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can attempt to inspect which tags are most common, in which combinations, and which words would be ideal\n",
    "for further additional metadata. However, **our tags are still lumped together** at this point. Also, there is\n",
    "reason to believe that **some tags are showing up multiple times in the same tag string**. In order to properly count tag frequency, the duplicates must be confirmed absent (ie. found & removed). Then, the occurance (word frequency) of each tag may then be summed up for the tags column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Inspect a note that you suspect has tag duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_note_by_id(df_in, nid):\n",
    "    return df_in[df_in['nid']==nid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that a particular note has tag duplicates\n",
    "# crimison note id: 1369286386384\n",
    "note_id_1 = 1369286386384\n",
    "assertEquals(inspect_note_by_id(df_notes_002_better_tags,note_id_1).tags.values[0],\"fromexam color fromexam len1\",\"Four tags total with two duplicates exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>Yomi3</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>1369286386384</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>fromexam color fromexam len1</td>\n",
       "      <td>紅</td>\n",
       "      <td>くれない</td>\n",
       "      <td>&lt;div&gt;deep red; crimson&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;&lt;div&gt;Common word, ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid         mod                          tags Term Yomi1  \\\n",
       "3847  1369286386384  1511481489  fromexam color fromexam len1    紅  くれない   \n",
       "\n",
       "                                            Translation Translation2  \\\n",
       "3847  <div>deep red; crimson</div><div><br /></div><...                \n",
       "\n",
       "     Translation3 AlternateForms  \\\n",
       "3847                               \n",
       "\n",
       "                                           PartOfSpeech  ...   Yomi3 gChap  \\\n",
       "3847  <div>Common word, Noun</div><div>Common word, ...  ...                 \n",
       "\n",
       "     gBook semester gNumber Transliteration SoloLookCards TagOverflow blank1  \\\n",
       "3847                                                                           \n",
       "\n",
       "     blank2  \n",
       "3847         \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of item with tag duplication\n",
    "sel2 = inspect_note_by_id(df_notes_002_better_tags,note_id_1)\n",
    "sel2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Remove duplicate tags (convert tag strings > lists > sets > strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a tag string to a list to a set back to a string (this removes the duplicates)\n",
    "def remove_dupes(t):\n",
    "    temp = list(set(t.lower().split()))\n",
    "    return ' '.join(temp) # return as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_003_tags_no_dups = df_notes_002_better_tags.copy()\n",
    "df_notes_003_tags_no_dups['tags'] = df_notes_003_tags_no_dups['tags'].apply(lambda x: remove_dupes(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if an individual tag substring exists in a larger tags list string\n",
    "def tag_exists(tags, tag):\n",
    "    return 1 if tag in tags.split() else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len1 fromexam color\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inspect_note_by_id(df_notes_003_tags_no_dups,note_id_1).tags.values[0])\n",
    "assertEquals(tag_exists(inspect_note_by_id(df_notes_003_tags_no_dups,note_id_1).tags.values[0],\"len1\"), 1, \"tag 'len1' remains\")\n",
    "assertEquals(tag_exists(inspect_note_by_id(df_notes_003_tags_no_dups,note_id_1).tags.values[0],\"fromexam\"), 1, \"tag 'fromexam' remains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we have most, if not all, of the data we need to start. The format of the dates though is not yet human readable. Let's fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Convert (& preserve) note ID to note creation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Term 臨機応変\n",
      "---------------------------------------------------------------------------\n",
      "Before: 1331799797110\n",
      "---------------------------------------------------------------------------\n",
      "After: 2012-03-15\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dueNum = 782 # this represents days from collection creation date\n",
    "#crt = 1357635600 # this represents the collection creation date #todo: query dynamically from database\n",
    "#print(\"mid 'model id': \" + time.ctime(int(\"1768161991\"))) # 1 day = 86400 seconds\n",
    "\n",
    "df_notes_004_with_date = df_notes_003_tags_no_dups.copy()\n",
    "df_notes_004_with_date['NoteCreated']= pd.to_datetime(df_notes_004_with_date['nid'],unit='ms')\n",
    "df_notes_004_with_date['NoteCreated'] = df_notes_004_with_date['NoteCreated'].dt.date\n",
    "df_notes_004_with_date.head()\n",
    "\n",
    "print_before_after(df_notes_003_tags_no_dups['nid'].iloc[0], df_notes_004_with_date['NoteCreated'].iloc[0],\"Term \" + df_notes_004_with_date['Term'].iloc[0])\n",
    "\n",
    "assertEquals(df_notes_004_with_date['nid'].iloc[0], 1331799797110, \"Note ID is in Epoch Units\")\n",
    "assertEquals(str(df_notes_004_with_date['NoteCreated'].iloc[0]), \"2012-03-15\", \"Note ID is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Generate Note Last Modified Date from \"Mod\" ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_005_last_modified = df_notes_004_with_date.copy()\n",
    "df_notes_005_last_modified['mod'] = pd.to_datetime(df_notes_005_last_modified['mod'],unit='s')\n",
    "df_notes_005_last_modified['mod'] = df_notes_005_last_modified['mod'].dt.date\n",
    "\n",
    "assertEquals(str(df_notes_005_last_modified['mod'].iloc[0]), \"2017-11-23\", \"Note last modified is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Create df_notes_final data frame for export & further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_final = df_notes_005_last_modified.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Export df_notes_section_2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_final.to_csv('datasets/notes_section_2_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Generate Card Creation Date from Card ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cards_002_created_date = df_cards_001_less_cols.copy()\n",
    "df_cards_002_created_date['CardCreated'] = pd.to_datetime(df_cards_002_created_date['id'],unit='ms')\n",
    "df_cards_002_created_date['CardCreated'] = df_cards_002_created_date['CardCreated'].dt.date\n",
    "\n",
    "assertEquals(str(df_cards_002_created_date['CardCreated'].iloc[0]), \"2012-03-15\", \"Card ID is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Card Rows:\n",
      "---------------------------------------------------------------------------\n",
      "Before: 19315\n",
      "---------------------------------------------------------------------------\n",
      "After: 8245\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nid</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18909</th>\n",
       "      <td>1549415185907</td>\n",
       "      <td>1549184119039</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2388</td>\n",
       "      <td>87</td>\n",
       "      <td>2410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18910</th>\n",
       "      <td>1550403009251</td>\n",
       "      <td>1550402953788</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2232</td>\n",
       "      <td>1</td>\n",
       "      <td>2410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18911</th>\n",
       "      <td>1550403009269</td>\n",
       "      <td>1550402953788</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2302</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18912</th>\n",
       "      <td>1550403084990</td>\n",
       "      <td>1550403040864</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2383</td>\n",
       "      <td>82</td>\n",
       "      <td>2410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18913</th>\n",
       "      <td>1550403085003</td>\n",
       "      <td>1550403040864</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2240</td>\n",
       "      <td>5</td>\n",
       "      <td>2410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            nid  ord  queue   due  ivl  factor  reps  \\\n",
       "18909  1549415185907  1549184119039    2      2  2388   87    2410     3   \n",
       "18910  1550403009251  1550402953788    0      2  2232    1    2410     3   \n",
       "18911  1550403009269  1550402953788    2      2  2302    1    2010     8   \n",
       "18912  1550403084990  1550403040864    0      2  2383   82    2410     3   \n",
       "18913  1550403085003  1550403040864    2      2  2240    5    2410     3   \n",
       "\n",
       "       lapses CardCreated  \n",
       "18909       0  2019-02-06  \n",
       "18910       0  2019-02-17  \n",
       "18911       2  2019-02-17  \n",
       "18912       0  2019-02-17  \n",
       "18913       0  2019-02-17  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#queue           integer not null,\n",
    "#      -- -3=sched buried, -2=user buried, -1=suspended,\n",
    "#      -- 0=new, 1=learning, 2=due (as for type)\n",
    "\n",
    "df_cards_003_no_new = df_cards_002_created_date.copy()\n",
    "df_cards_003_no_new = df_cards_003_no_new[df_cards_003_no_new['queue']!=0] # remove cards marked as new\n",
    "df_cards_003_no_new = df_cards_003_no_new[df_cards_003_no_new['reps']!=0] # remove cards that have not been reviewed\n",
    "df_cards_003_no_new = df_cards_003_no_new[df_cards_003_no_new['queue']!=-1] # remove cards that are currently suspended\n",
    "# https://stackoverflow.com/questions/18196203/how-to-conditionally-update-dataframe-column-in-pandas\n",
    "df_cards_003_no_new.loc[df_cards_003_no_new['due'] > 10000, 'due'] = 0 # assign 0 to the due # todo: update w/ last studied date from revlog # todo: comment this line out once you have updated the collection import\n",
    "\n",
    "print_before_after(df_cards_002_created_date.shape[0], df_cards_003_no_new.shape[0],\"Card Rows:\")\n",
    "\n",
    "df_cards_003_no_new.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nid</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, nid, ord, queue, due, ivl, factor, reps, lapses, CardCreated]\n",
       "Index: []"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo: add assertion to confirm that sel3 is empty (row size of 0)\n",
    "# confirm that the three cards \"in learning\" have their due dates reset back to 0 for date transformation\n",
    "sel3 = df_cards_003_no_new[df_cards_003_no_new['due'] == 0]\n",
    "sel3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Generate Due Date from Due Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cards_004_due_date = df_cards_003_no_new.copy()\n",
    "df_cards_004_due_date['due'] = pd_crt + df_cards_004_due_date['due'].map(timedelta)\n",
    "df_cards_004_due_date['due'] = df_cards_004_due_date['due'].dt.date\n",
    "\n",
    "assertEquals(str(df_cards_004_due_date['due'].iloc[0]), \"2015-03-08\", \"Card due date is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Create df_cards_final data frame for export & further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards_final = df_cards_004_due_date.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Export df_cards_section_2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards_final.to_csv('datasets/cards_section_2_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. Merge card & note data frames to conduct cross analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8245, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797110</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>rare fromdict idiom</td>\n",
       "      <td>臨機応変</td>\n",
       "      <td>りんきおうへん</td>\n",
       "      <td>adapting oneself to the requirements of the mo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun, No-adjective</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-08</td>\n",
       "      <td>65</td>\n",
       "      <td>1680</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797112</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>149</td>\n",
       "      <td>2080</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797114</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>移籍</td>\n",
       "      <td>いせき</td>\n",
       "      <td>&lt;div&gt;changing household registry; transfer (e....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun, Suru verb&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797114</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>99</td>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1331799797117</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict verb</td>\n",
       "      <td>吊るす</td>\n",
       "      <td>つるす</td>\n",
       "      <td>to hang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>143</td>\n",
       "      <td>2130</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1331799797118</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict checked convo</td>\n",
       "      <td>和やか</td>\n",
       "      <td>なごやか</td>\n",
       "      <td>harmonious, peaceful</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797118</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-06</td>\n",
       "      <td>74</td>\n",
       "      <td>1880</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod                    tags  Term    Yomi1  \\\n",
       "0  1331799797110  2017-11-23     rare fromdict idiom  臨機応変  りんきおうへん   \n",
       "1  1331799797112  2017-11-23                fromdict    隙間      すきま   \n",
       "2  1331799797114  2017-11-23                fromdict    移籍      いせき   \n",
       "3  1331799797117  2017-11-23           fromdict verb   吊るす      つるす   \n",
       "4  1331799797118  2017-11-23  fromdict checked convo   和やか     なごやか   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "0  adapting oneself to the requirements of the mo...                \n",
       "1            <div>crevice; crack; gap; opening</div>                \n",
       "2  <div>changing household registry; transfer (e....                \n",
       "3                                            to hang                \n",
       "4                               harmonious, peaceful                \n",
       "\n",
       "  Translation3 AlternateForms                             PartOfSpeech  \\\n",
       "0                                                   Noun, No-adjective   \n",
       "1                                         <div>Common word, Noun</div>   \n",
       "2                              <div>Common word, Noun, Suru verb</div>   \n",
       "3                                                                        \n",
       "4                                                                        \n",
       "\n",
       "      ...     NoteCreated             id ord queue         due  ivl factor  \\\n",
       "0     ...      2012-03-15  1331799797110   0     2  2015-03-08   65   1680   \n",
       "1     ...      2012-03-15  1331799797112   0     2  2015-03-03  149   2080   \n",
       "2     ...      2012-03-15  1331799797114   0     2  2015-02-04   99   1980   \n",
       "3     ...      2012-03-15  1331799797117   0     2  2015-03-17  143   2130   \n",
       "4     ...      2012-03-15  1331799797118   0     2  2015-02-06   74   1880   \n",
       "\n",
       "  reps lapses CardCreated  \n",
       "0   10      1  2012-03-15  \n",
       "1    8      1  2012-03-15  \n",
       "2    7      0  2012-03-15  \n",
       "3    6      1  2012-03-15  \n",
       "4   15      3  2012-03-15  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that we have note id's for all the words, we can\n",
    "# join together these separate dataframes\n",
    "df_combo = pd.merge(df_notes_final, df_cards_final, on='nid')\n",
    "print(df_combo.shape)\n",
    "df_combo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that card types are being rendered as numbers, which makes it less human readible. We will fix this. Additionally, our card model has a bunch of columns (fields) with no values in them, whatsoever. These can be taken out for the data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blank (s):\n",
    "    return not (s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_of_cards_by_term(df, t):\n",
    "    return df.loc[df['Term']==t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>1354094556789</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>commonword fromtest suruverb noun textbook n3</td>\n",
       "      <td>発明</td>\n",
       "      <td>はつめい</td>\n",
       "      <td>&lt;span style=\"\"&gt;&lt;div&gt;invention&lt;/div&gt;&lt;/span&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Common word, Noun, Suru verb</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>1354094556789</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>80</td>\n",
       "      <td>1300</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>1354094556789</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>commonword fromtest suruverb noun textbook n3</td>\n",
       "      <td>発明</td>\n",
       "      <td>はつめい</td>\n",
       "      <td>&lt;span style=\"\"&gt;&lt;div&gt;invention&lt;/div&gt;&lt;/span&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Common word, Noun, Suru verb</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>1371807076626</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>1056</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid         mod  \\\n",
       "2899  1354094556789  2018-12-03   \n",
       "2900  1354094556789  2018-12-03   \n",
       "\n",
       "                                               tags Term Yomi1  \\\n",
       "2899  commonword fromtest suruverb noun textbook n3   発明  はつめい   \n",
       "2900  commonword fromtest suruverb noun textbook n3   発明  はつめい   \n",
       "\n",
       "                                     Translation Translation2 Translation3  \\\n",
       "2899  <span style=\"\"><div>invention</div></span>                             \n",
       "2900  <span style=\"\"><div>invention</div></span>                             \n",
       "\n",
       "     AlternateForms                  PartOfSpeech     ...     NoteCreated  \\\n",
       "2899                 Common word, Noun, Suru verb     ...      2012-11-28   \n",
       "2900                 Common word, Noun, Suru verb     ...      2012-11-28   \n",
       "\n",
       "                 id ord queue         due   ivl factor reps lapses CardCreated  \n",
       "2899  1354094556789   0     2  2015-06-30    80   1300   73      9  2012-11-28  \n",
       "2900  1371807076626   4     2  2021-10-24  1056   1300   20      0  2013-06-21  \n",
       "\n",
       "[2 rows x 66 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look a a small slice of data, to infer what we may\n",
    "# we can take a broad overview look at the dataset to more quickly isolate candidates for removal\n",
    "s = get_frame_of_cards_by_term(df_combo, '発明')\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. Determine which columns (fields) are unused & can be safely removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal candidates: ['Sound3', 'AtoQ', 'AtoQaudio', 'AtoQkana', 'AtoQtranslation', 'QandApicture', 'answerPicture', 'blank1', 'blank2']\n"
     ]
    }
   ],
   "source": [
    "col_names = df_combo.columns.values\n",
    "#print(is_blank(df_combo['Translation2'].iloc[0])) # see that this cell for this row is indeed blank\n",
    "\n",
    "row_cnt = df_combo.shape[0] # number of rows in df_combo\n",
    "\n",
    "# https://stackoverflow.com/questions/49677060/pandas-count-empty-strings-in-a-column\n",
    "empty_strings = pd.DataFrame(df_combo.values == '',columns=col_names) # find all empty strings in a DataFrame\n",
    "temp_dict = (empty_strings.sum()).to_dict()  # save the location of all empty strings as a DataFrame of booleans\n",
    "removal_candidates = []\n",
    "for key in temp_dict.items():\n",
    "    if key[1] == row_cnt:\n",
    "        removal_candidates.append(key[0])\n",
    "print(\"Removal candidates:\", removal_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. Trim unneeded (empty) columns from combo data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Before: (8245, 66)\n",
      "---------------------------------------------------------------------------\n",
      "After: (8245, 56)\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "Before: ['nid' 'mod' 'tags' 'Term' 'Yomi1' 'Translation' 'Translation2'\n",
      " 'Translation3' 'AlternateForms' 'PartOfSpeech' 'Sound' 'Sound2' 'Sound3'\n",
      " 'Examples' 'ExamplesAudio' 'AtoQ' 'AtoQaudio' 'AtoQkana'\n",
      " 'AtoQtranslation' 'QandApicture' 'answerPicture' 'Meaning1'\n",
      " 'SimilarWords' 'RelatedWords' 'Breakdown1' 'Comparison' 'Usage' 'Prompt1'\n",
      " 'Prompt2' 'KakuMCD' 'IuMCD' 'ExtraMemo' 'Yomi2' 'Meaning2' 'Breakdown2'\n",
      " 'Picture1' 'Picture2' 'Picture3' 'Picture4' 'HinshiMarker' 'Hint' 'Term2'\n",
      " 'ArabicNumeral' 'CounterKanji' 'Mnemonic' 'SameSoundWords' 'Yomi3'\n",
      " 'gChap' 'gBook' 'semester' 'gNumber' 'Transliteration' 'SoloLookCards'\n",
      " 'TagOverflow' 'blank1' 'blank2' 'NoteCreated' 'id' 'ord' 'queue' 'due'\n",
      " 'ivl' 'factor' 'reps' 'lapses' 'CardCreated']\n",
      "---------------------------------------------------------------------------\n",
      "After: ['nid' 'mod' 'tags' 'Term' 'Yomi1' 'Translation' 'Translation2'\n",
      " 'Translation3' 'AlternateForms' 'PartOfSpeech' 'Sound' 'Sound2'\n",
      " 'Examples' 'ExamplesAudio' 'Meaning1' 'SimilarWords' 'RelatedWords'\n",
      " 'Breakdown1' 'Comparison' 'Usage' 'Prompt1' 'Prompt2' 'KakuMCD' 'IuMCD'\n",
      " 'ExtraMemo' 'Yomi2' 'Meaning2' 'Breakdown2' 'Picture1' 'Picture2'\n",
      " 'Picture3' 'Picture4' 'HinshiMarker' 'Hint' 'Term2' 'ArabicNumeral'\n",
      " 'CounterKanji' 'Mnemonic' 'SameSoundWords' 'Yomi3' 'gChap' 'gBook'\n",
      " 'semester' 'gNumber' 'Transliteration' 'SoloLookCards' 'TagOverflow'\n",
      " 'NoteCreated' 'id' 'ord' 'due' 'ivl' 'factor' 'reps' 'lapses'\n",
      " 'CardCreated']\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_combo_001_less_cols = df_combo.copy()\n",
    "\n",
    "removal_list = list(removal_candidates + ['queue'])\n",
    "\n",
    "df_combo_001_less_cols = df_combo_001_less_cols.drop(removal_list,axis=1)\n",
    "\n",
    "print_before_after(df_combo.shape, df_combo_001_less_cols.shape)\n",
    "print_before_after(df_combo.columns.values, df_combo_001_less_cols.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31. Label card types by their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     6843\n",
      "4     1115\n",
      "7      274\n",
      "2       11\n",
      "11       2\n",
      "Name: ord, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "read      6843\n",
       "look      1115\n",
       "listen     274\n",
       "recall      11\n",
       "Name: CardType, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ord stands for 'ordinal' : identifies which of the card templates it corresponds to\n",
    "print(df_combo_001_less_cols['ord'].value_counts()) # these are the card vectors\n",
    "\n",
    "# since our dataset contains a single card of a single card vector, & the card vectors\n",
    "# aren't named/labeled, let's remove the outlier & add the names\n",
    "df_combo_002_types_labeled = df_combo_001_less_cols.copy()\n",
    "df_combo_002_types_labeled = df_combo_002_types_labeled.drop(df_combo_002_types_labeled[df_combo_002_types_labeled['ord'] == 11].index)\n",
    "\n",
    "df_combo_002_types_labeled['ord'].value_counts() # the check shall pass\n",
    "\n",
    "# now, to map the names onto the card vectors\n",
    "df_combo_002_types_labeled['CardType'] = df_combo_002_types_labeled['ord'].map({0:'read', 2:'recall',4:'look',7:'listen'})\n",
    "df_combo_002_types_labeled['CardType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Create binary exists/not columns based on presence of a given tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_by_tag(df, tag):\n",
    "    df[tag] = df['tags'].apply(lambda x: tag_exists(str(x), tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_003_with_binary = df_combo_002_types_labeled.copy()\n",
    "inspect_list = [\"commonword\", \"clothing\", \"animal\", \"body\", \"food\", \"place\",\n",
    "                \"textbook\", \"college\", \"fromdict\", \"fromexam\",\n",
    "                \"len1\", \"n1\", \"n2\", \"n3\", \"n4\", \"n5\"\n",
    "               ]\n",
    "for item in inspect_list:\n",
    "    add_column_by_tag(df_combo_003_with_binary, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    50\n",
       "int64     23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_003_with_binary.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Create interval quartile sections for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>college</th>\n",
       "      <th>fromdict</th>\n",
       "      <th>fromexam</th>\n",
       "      <th>len1</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>ivl_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797110</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>rare fromdict idiom</td>\n",
       "      <td>臨機応変</td>\n",
       "      <td>りんきおうへん</td>\n",
       "      <td>adapting oneself to the requirements of the mo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun, No-adjective</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797114</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>移籍</td>\n",
       "      <td>いせき</td>\n",
       "      <td>&lt;div&gt;changing household registry; transfer (e....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun, Suru verb&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1331799797117</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict verb</td>\n",
       "      <td>吊るす</td>\n",
       "      <td>つるす</td>\n",
       "      <td>to hang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1331799797118</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict checked convo</td>\n",
       "      <td>和やか</td>\n",
       "      <td>なごやか</td>\n",
       "      <td>harmonious, peaceful</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod                    tags  Term    Yomi1  \\\n",
       "0  1331799797110  2017-11-23     rare fromdict idiom  臨機応変  りんきおうへん   \n",
       "1  1331799797112  2017-11-23                fromdict    隙間      すきま   \n",
       "2  1331799797114  2017-11-23                fromdict    移籍      いせき   \n",
       "3  1331799797117  2017-11-23           fromdict verb   吊るす      つるす   \n",
       "4  1331799797118  2017-11-23  fromdict checked convo   和やか     なごやか   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "0  adapting oneself to the requirements of the mo...                \n",
       "1            <div>crevice; crack; gap; opening</div>                \n",
       "2  <div>changing household registry; transfer (e....                \n",
       "3                                            to hang                \n",
       "4                               harmonious, peaceful                \n",
       "\n",
       "  Translation3 AlternateForms                             PartOfSpeech  ...   \\\n",
       "0                                                   Noun, No-adjective  ...    \n",
       "1                                         <div>Common word, Noun</div>  ...    \n",
       "2                              <div>Common word, Noun, Suru verb</div>  ...    \n",
       "3                                                                       ...    \n",
       "4                                                                       ...    \n",
       "\n",
       "  college fromdict fromexam len1 n1 n2 n3 n4 n5 ivl_q  \n",
       "0       0        1        0    0  0  0  0  0  0     0  \n",
       "1       0        1        0    0  0  0  0  0  0     1  \n",
       "2       0        1        0    0  0  0  0  0  0     0  \n",
       "3       0        1        0    0  0  0  0  0  0     0  \n",
       "4       0        1        0    0  0  0  0  0  0     0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qcut: Quantile-based discretization function. Discretize variable into equal-sized buckets\n",
    "# based on rank or based on sample quantiles. For example 1000 values for 10 quantiles would\n",
    "# produce a Categorical object indicating quantile membership for each data point.\n",
    "# http://www.datasciencemadesimple.com/quantile-decile-rank-column-pandas-python-2/\n",
    "df_combo_003_with_binary['ivl_q'] = pd.qcut(df_combo_003_with_binary['ivl'],5,labels=False)\n",
    "df_combo_003_with_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further refine the dataframe entries to represent which notes have (1) visual data, (2) audio data, and (3) a L1 (\"first language\", English in this case) translation. We can represent these with binary values (0 for doesn't exist, 1 for exists)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. Create boolean columns for predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura calls this process \"Data Enriching\"\n",
    "intify_list = ['hasPOS','hasVisual','hasAudio','hasMultiMeaning','hasMultiReading','hasSimilar','hasHomophone','hasAltForm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/17383094/how-can-i-map-true-false-to-1-0-in-a-pandas-dataframe\n",
    "df_combo_003_with_binary['hasPOS'] = df_combo_003_with_binary['PartOfSpeech']!=\"\" #todo: expand upon this, by tagify\n",
    "df_combo_003_with_binary['hasVisual'] = df_combo_003_with_binary['Picture1']!=\"\"\n",
    "df_combo_003_with_binary['hasAudio'] = df_combo_003_with_binary['Sound']!=\"\"\n",
    "df_combo_003_with_binary['hasMultiMeaning'] = df_combo_003_with_binary['Translation2' and 'Translation3' and 'Meaning2']!=\"\"\n",
    "df_combo_003_with_binary['hasMultiReading'] = df_combo_003_with_binary['Yomi2']!=\"\" # todo: inspect & incorporate venn diagram: https://commons.wikimedia.org/wiki/File:Homograph_homophone_venn_diagram.png\n",
    "df_combo_003_with_binary['hasSimilar'] = df_combo_003_with_binary['SimilarWords']!=\"\"\n",
    "df_combo_003_with_binary['hasHomophone'] = df_combo_003_with_binary['SameSoundWords']!=\"\" # write function, detect homophones\n",
    "df_combo_003_with_binary['hasAltForm'] = df_combo_003_with_binary['Term2' and 'AlternateForms']!= \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. Drop non-numerical columns from combo data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_004_less_cols = df_combo_003_with_binary.copy()\n",
    "df_combo_004_less_cols = df_combo_004_less_cols.drop(['Examples','ExamplesAudio',\n",
    "                            'Meaning1','RelatedWords','Breakdown1','Comparison',\n",
    "                           'Usage','Prompt1','Prompt2','KakuMCD','IuMCD','ExtraMemo',\n",
    "                           'Breakdown2','Picture2','Picture3','Picture4','Mnemonic',\n",
    "                            'Yomi3','gChap','gBook','semester','gNumber','ArabicNumeral',\n",
    "                            'CounterKanji','SoloLookCards','HinshiMarker','Hint',\n",
    "                            'mod','Transliteration'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casts columns of type object to type int as directed, use with caution\n",
    "def intify_bools(df, col):\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. Ensure numerical/boolean types are encoded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     24\n",
       "object    21\n",
       "bool       8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_004_less_cols.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in intify_list:\n",
    "    intify_bools(df_combo_004_less_cols,item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     32\n",
       "object    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_004_less_cols.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. Further reduce columns not in use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>due</th>\n",
       "      <th>...</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>ivl_q</th>\n",
       "      <th>hasVisual</th>\n",
       "      <th>hasAudio</th>\n",
       "      <th>hasMultiMeaning</th>\n",
       "      <th>hasMultiReading</th>\n",
       "      <th>hasSimilar</th>\n",
       "      <th>hasHomophone</th>\n",
       "      <th>hasAltForm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1342506824723</td>\n",
       "      <td>media len1 ghibli textbook suffix magazine</td>\n",
       "      <td>者</td>\n",
       "      <td>もの</td>\n",
       "      <td>&lt;span style=\"\"&gt;person (rarely used w.o. a qual...</td>\n",
       "      <td>&lt;span style=\"\"&gt;Common word, Noun&lt;/span&gt;&lt;div&gt;No...</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824723</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1342506824724</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>事件</td>\n",
       "      <td>じけん</td>\n",
       "      <td>event; affair; incident; case; plot; trouble; ...</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824724</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1342506824725</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>事情</td>\n",
       "      <td>じじょう</td>\n",
       "      <td>circumstances; consideration; conditions; situ...</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824725</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1342506824726</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>事柄</td>\n",
       "      <td>ことがら</td>\n",
       "      <td>matter; thing; affair; circumstance</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824726</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1342506824727</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>物事</td>\n",
       "      <td>ものごと</td>\n",
       "      <td>things; everything</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824727</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nid                                        tags Term Yomi1  \\\n",
       "30  1342506824723  media len1 ghibli textbook suffix magazine    者    もの   \n",
       "31  1342506824724                                    fromdict   事件   じけん   \n",
       "32  1342506824725                                    fromdict   事情  じじょう   \n",
       "33  1342506824726                                    fromdict   事柄  ことがら   \n",
       "34  1342506824727                                    fromdict   物事  ものごと   \n",
       "\n",
       "                                          Translation  \\\n",
       "30  <span style=\"\">person (rarely used w.o. a qual...   \n",
       "31  event; affair; incident; case; plot; trouble; ...   \n",
       "32  circumstances; consideration; conditions; situ...   \n",
       "33                matter; thing; affair; circumstance   \n",
       "34                                things; everything    \n",
       "\n",
       "                                         PartOfSpeech NoteCreated  \\\n",
       "30  <span style=\"\">Common word, Noun</span><div>No...  2012-07-17   \n",
       "31                                  Common word, Noun  2012-07-17   \n",
       "32                                  Common word, Noun  2012-07-17   \n",
       "33                                  Common word, Noun  2012-07-17   \n",
       "34                                  Common word, Noun  2012-07-17   \n",
       "\n",
       "               id  ord         due     ...      n4  n5  ivl_q  hasVisual  \\\n",
       "30  1342506824723    0  2016-12-01     ...       0   0      4          0   \n",
       "31  1342506824724    0  2015-05-07     ...       0   0      2          0   \n",
       "32  1342506824725    0  2015-07-10     ...       0   0      2          0   \n",
       "33  1342506824726    0  2015-11-10     ...       0   0      2          0   \n",
       "34  1342506824727    0  2016-03-17     ...       0   0      2          0   \n",
       "\n",
       "   hasAudio hasMultiMeaning  hasMultiReading  hasSimilar  hasHomophone  \\\n",
       "30        0               0                0           0             0   \n",
       "31        0               0                0           0             0   \n",
       "32        0               0                0           0             0   \n",
       "33        0               0                0           1             0   \n",
       "34        0               0                0           1             0   \n",
       "\n",
       "    hasAltForm  \n",
       "30           0  \n",
       "31           0  \n",
       "32           0  \n",
       "33           0  \n",
       "34           0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_004_less_cols = df_combo_004_less_cols.drop(['Picture1','Sound','Sound2',\n",
    "                              'TagOverflow','Translation2', 'Meaning2','Yomi2','Term2',\n",
    "                              'SameSoundWords','hasPOS','SimilarWords','AlternateForms',\n",
    "                            'Translation3'],axis=1)\n",
    "df_combo_004_less_cols.head(35)[30:]\n",
    "\n",
    "#selection2 = df_binary.loc[df_binary['hasMultiMeaning']==1]\n",
    "#selection2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. Count syllable count & character length for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>due</th>\n",
       "      <th>...</th>\n",
       "      <th>hasVisual</th>\n",
       "      <th>hasAudio</th>\n",
       "      <th>hasMultiMeaning</th>\n",
       "      <th>hasMultiReading</th>\n",
       "      <th>hasSimilar</th>\n",
       "      <th>hasHomophone</th>\n",
       "      <th>hasAltForm</th>\n",
       "      <th>TermLen</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>TermLenGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>1485705402623</td>\n",
       "      <td>commonword clothing noun gairaigo katakana</td>\n",
       "      <td>ブラジャー</td>\n",
       "      <td></td>\n",
       "      <td>1. bra; brassiere</td>\n",
       "      <td></td>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>1485707774754</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>1489373157595</td>\n",
       "      <td></td>\n",
       "      <td>細切り</td>\n",
       "      <td>ほそぎり</td>\n",
       "      <td>thin strips; matchstick-like strips; julienned...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>1489373228966</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8227</th>\n",
       "      <td>1489756408272</td>\n",
       "      <td></td>\n",
       "      <td>離陸</td>\n",
       "      <td>りりく</td>\n",
       "      <td>take-off (getting off the ground)</td>\n",
       "      <td></td>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>1489756526501</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8228</th>\n",
       "      <td>1508007342589</td>\n",
       "      <td>phrases basics commonword kana</td>\n",
       "      <td>どういたしまして</td>\n",
       "      <td></td>\n",
       "      <td>you are welcome; don't mention it; not at all;...</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1508007536099</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>1508007342589</td>\n",
       "      <td>phrases basics commonword kana</td>\n",
       "      <td>どういたしまして</td>\n",
       "      <td></td>\n",
       "      <td>you are welcome; don't mention it; not at all;...</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1508007536100</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8230</th>\n",
       "      <td>1508007536188</td>\n",
       "      <td>phrase basics formal polite question</td>\n",
       "      <td>お名前は何ですか？</td>\n",
       "      <td>おなまえ は なん ですか？</td>\n",
       "      <td>What is your name?</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1508007825484</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8231</th>\n",
       "      <td>1508012628565</td>\n",
       "      <td>basics n5 kana commonword</td>\n",
       "      <td>いいえ</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1508013224329</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-24</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8232</th>\n",
       "      <td>1508012628565</td>\n",
       "      <td>basics n5 kana commonword</td>\n",
       "      <td>いいえ</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1511480991113</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8233</th>\n",
       "      <td>1508012628565</td>\n",
       "      <td>basics n5 kana commonword</td>\n",
       "      <td>いいえ</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1511480991114</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>1508012628565</td>\n",
       "      <td>basics n5 kana commonword</td>\n",
       "      <td>いいえ</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1511480991115</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid                                        tags       Term  \\\n",
       "8225  1485705402623  commonword clothing noun gairaigo katakana      ブラジャー   \n",
       "8226  1489373157595                                                    細切り   \n",
       "8227  1489756408272                                                     離陸   \n",
       "8228  1508007342589              phrases basics commonword kana   どういたしまして   \n",
       "8229  1508007342589              phrases basics commonword kana   どういたしまして   \n",
       "8230  1508007536188        phrase basics formal polite question  お名前は何ですか？   \n",
       "8231  1508012628565                   basics n5 kana commonword        いいえ   \n",
       "8232  1508012628565                   basics n5 kana commonword        いいえ   \n",
       "8233  1508012628565                   basics n5 kana commonword        いいえ   \n",
       "8234  1508012628565                   basics n5 kana commonword        いいえ   \n",
       "\n",
       "               Yomi1                                        Translation  \\\n",
       "8225                                                  1. bra; brassiere   \n",
       "8226            ほそぎり  thin strips; matchstick-like strips; julienned...   \n",
       "8227             りりく                 take-off (getting off the ground)    \n",
       "8228                  you are welcome; don't mention it; not at all;...   \n",
       "8229                  you are welcome; don't mention it; not at all;...   \n",
       "8230  おなまえ は なん ですか？                                 What is your name?   \n",
       "8231                                                                 no   \n",
       "8232                                                                 no   \n",
       "8233                                                                 no   \n",
       "8234                                                                 no   \n",
       "\n",
       "     PartOfSpeech NoteCreated             id  ord         due      ...       \\\n",
       "8225               2017-01-29  1485707774754    4  2019-05-02      ...        \n",
       "8226         Noun  2017-03-13  1489373228966    0  2017-03-25      ...        \n",
       "8227               2017-03-17  1489756526501    0  2017-03-18      ...        \n",
       "8228               2017-10-14  1508007536099    0  2018-07-19      ...        \n",
       "8229               2017-10-14  1508007536100    7  2018-08-16      ...        \n",
       "8230               2017-10-14  1508007825484    7  2018-06-18      ...        \n",
       "8231               2017-10-14  1508013224329    0  2018-03-24      ...        \n",
       "8232               2017-10-14  1511480991113    2  2019-05-02      ...        \n",
       "8233               2017-10-14  1511480991114    4  2018-03-22      ...        \n",
       "8234               2017-10-14  1511480991115    7  2018-03-22      ...        \n",
       "\n",
       "      hasVisual  hasAudio  hasMultiMeaning  hasMultiReading hasSimilar  \\\n",
       "8225          1         0                0                0          0   \n",
       "8226          0         0                0                0          0   \n",
       "8227          0         0                0                0          0   \n",
       "8228          1         1                0                0          0   \n",
       "8229          1         1                0                0          0   \n",
       "8230          0         1                0                0          0   \n",
       "8231          1         1                0                0          0   \n",
       "8232          1         1                0                0          0   \n",
       "8233          1         1                0                0          0   \n",
       "8234          1         1                0                0          0   \n",
       "\n",
       "     hasHomophone  hasAltForm  TermLen  Syllables  TermLenGroup  \n",
       "8225            0           0        5          5         [5:8]  \n",
       "8226            0           0        3          4         [3:4]  \n",
       "8227            0           0        2          3           [2]  \n",
       "8228            0           0        8          8         [5:8]  \n",
       "8229            0           0        8          8         [5:8]  \n",
       "8230            0           0        9         14         [9: ]  \n",
       "8231            0           0        3          3         [3:4]  \n",
       "8232            0           0        3          3         [3:4]  \n",
       "8233            0           0        3          3         [3:4]  \n",
       "8234            0           0        3          3         [3:4]  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_005_with_len = df_combo_004_less_cols.copy()\n",
    "\n",
    "df_combo_005_with_len['TermLen'] = df_combo_005_with_len['Term'].str.len()\n",
    "df_combo_005_with_len['Syllables'] = df_combo_005_with_len['Yomi1'].str.len()\n",
    "df_combo_005_with_len.loc[df_combo_005_with_len['Syllables'] == 0, 'Syllables'] = df_combo_005_with_len['TermLen']\n",
    "\n",
    "bins = [0,1,2,4,8,128]\n",
    "labels = [\"[1]\",\"[2]\",\"[3:4]\",\"[5:8]\",\"[9: ]\"]\n",
    "# https://stackoverflow.com/questions/45273731/binning-column-with-python-pandas\n",
    "df_combo_005_with_len['TermLenGroup'] = pd.cut(df_combo_005_with_len['TermLen'], bins=bins, labels=labels)\n",
    "\n",
    "#df.loc[df['Grades'] <= 77, 'Grades'] = 100\n",
    "# https://stackoverflow.com/questions/42815768/pandas-adding-column-with-the-length-of-other-column-as-value\n",
    "#df_binary2.head(35)[30:]\n",
    "df_combo_005_with_len.tail(20)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>due</th>\n",
       "      <th>...</th>\n",
       "      <th>hasVisual</th>\n",
       "      <th>hasAudio</th>\n",
       "      <th>hasMultiMeaning</th>\n",
       "      <th>hasMultiReading</th>\n",
       "      <th>hasSimilar</th>\n",
       "      <th>hasHomophone</th>\n",
       "      <th>hasAltForm</th>\n",
       "      <th>TermLen</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>TermLenGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1346057958628</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>東京電力福島・第１原発事故</td>\n",
       "      <td>とうきょうでんりょくふくしま・だいいちげんぱつじこ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-08-27</td>\n",
       "      <td>1346057958628</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1346215143756</td>\n",
       "      <td>datesandtime fromdict numeric</td>\n",
       "      <td>1837～1901年</td>\n",
       "      <td>せんはっぴゃくさんじゅうななねんからせんきゅうひゃくいちねん</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>1346215143756</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               nid                           tags           Term  \\\n",
       "247  1346057958628                       fromdict  東京電力福島・第１原発事故   \n",
       "316  1346215143756  datesandtime fromdict numeric     1837～1901年   \n",
       "\n",
       "                              Yomi1 Translation PartOfSpeech NoteCreated  \\\n",
       "247       とうきょうでんりょくふくしま・だいいちげんぱつじこ                           2012-08-27   \n",
       "316  せんはっぴゃくさんじゅうななねんからせんきゅうひゃくいちねん                           2012-08-29   \n",
       "\n",
       "                id  ord         due      ...       hasVisual  hasAudio  \\\n",
       "247  1346057958628    0  2015-07-07      ...               0         0   \n",
       "316  1346215143756    0  2015-07-14      ...               0         0   \n",
       "\n",
       "     hasMultiMeaning  hasMultiReading hasSimilar hasHomophone  hasAltForm  \\\n",
       "247                0                0          0            0           0   \n",
       "316                0                0          0            0           0   \n",
       "\n",
       "     TermLen  Syllables  TermLenGroup  \n",
       "247       13         25         [9: ]  \n",
       "316       10         30         [9: ]  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the many syllable entries\n",
    "df_many_syl = df_combo_005_with_len.copy()\n",
    "many_syl = df_many_syl['Syllables'] > 20\n",
    "df_many_syl.loc[many_syl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nid', 'tags', 'Term', 'Yomi1', 'Translation', 'PartOfSpeech',\n",
       "       'NoteCreated', 'id', 'ord', 'due', 'ivl', 'factor', 'reps',\n",
       "       'lapses', 'CardCreated', 'CardType', 'commonword', 'clothing',\n",
       "       'animal', 'body', 'food', 'place', 'textbook', 'college',\n",
       "       'fromdict', 'fromexam', 'len1', 'n1', 'n2', 'n3', 'n4', 'n5',\n",
       "       'ivl_q', 'hasVisual', 'hasAudio', 'hasMultiMeaning',\n",
       "       'hasMultiReading', 'hasSimilar', 'hasHomophone', 'hasAltForm',\n",
       "       'TermLen', 'Syllables', 'TermLenGroup'], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_005_with_len.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
