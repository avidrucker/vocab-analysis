{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab Analysis \n",
    "## Section 4: Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime, timedelta, date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt # import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic correlogram\n",
    "sns.pairplot(df_explore)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a scatterplot\n",
    "#todo: give this graph a title\n",
    "#todo: rename \"lapses\" & \"reps\" to be \"Forgot Count\" and \"Review Count\"\n",
    "# graph 001\n",
    "#todo: increase in size, make sure data points are not obscured\n",
    "def stuff_1():\n",
    "    ax = sns.lmplot(x='reps', y='lapses', height=6, aspect=1.5, data=df_new_cols, \n",
    "                    fit_reg=False, #remove regression line\n",
    "                    hue='ivl_q',\n",
    "                    legend_out = True\n",
    "                   )\n",
    "    ax.set(xlabel='Card Reviews', ylabel='Card Fails')\n",
    "    new_title = 'Card\\nInterval\\nQuintile'\n",
    "    ax._legend.set_title(new_title)\n",
    "    plt.show()\n",
    "    \n",
    "time_it(stuff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph 002\n",
    "# by comparing repetition count to memory interval,\n",
    "# we can assess the approx. \"work\" or \"effort\" done to remember a card\n",
    "def stuff_2():\n",
    "    ax = sns.lmplot(x='ivl', y='reps', height=6, aspect=1.5, data=df_new_cols, \n",
    "                    fit_reg=False, #remove regression line\n",
    "                    hue='ivl_q',\n",
    "                    legend_out = True\n",
    "                   )\n",
    "    ax.set(xlabel='Card Interval', ylabel='Card Reviews')\n",
    "    new_title = 'Card\\nInterval\\nQuintile'\n",
    "    ax._legend.set_title(new_title)\n",
    "    plt.show()\n",
    "    \n",
    "time_it(stuff_2)\n",
    "\n",
    "# todo: rename ivl to \"How Long The Word Will Last in Memory in Days\"\n",
    "# todo: color code words here by (1) learning vector, (2) in terms of timedelta since first studied, and/or (3) by certain tags such as 'animal','verb' or 'commonword'\n",
    "# todo: (4) color code by word length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1:\n",
    "\n",
    "How does the above chart compare with the variation in ease over interval? Can this be used to determine \"typically memory resistant\" (non-sticky) words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph 003\n",
    "def stuff_3():\n",
    "    ax = sns.lmplot(x='ivl', y='factor', height=6, aspect=1.5, data=df_new_cols, \n",
    "                    hue='commonword'\n",
    "                    #legend_out = True\n",
    "                   )\n",
    "    ax.set(xlabel='Card Interval', ylabel='Ease Factor')\n",
    "    #new_title = 'Card\\nInterval\\nQuintile'\n",
    "    #ax._legend.set_title(new_title)\n",
    "    plt.show()\n",
    "    \n",
    "time_it(stuff_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2:\n",
    "\n",
    "What is unique (or what can we generalize) about the words that have very high repetition counts for lower (under 100) intervals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to understand the words conceptually: abstract vs concrete, verbs vs nouns vs adjectives\n",
    "# todo: conduct data entry to add concrete boolean for each note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stuff_4():\n",
    "    ax = sns.lmplot(x='factor', y='ivl', height=6, aspect=1.5, data=df_binary2, \n",
    "                    #fit_reg=False, #remove regression line\n",
    "                    hue='TermLenGroup',\n",
    "                    legend_out = True\n",
    "                   )\n",
    "    ax.set(xlabel='Ease Factor', ylabel='Card Interval')\n",
    "    new_title = 'Term Length Group'\n",
    "    ax._legend.set_title(new_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We see work harder work demonstrated for longer words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_it(stuff_4)\n",
    "# todo: color code words here by (1) learning vector\n",
    "# (2) in terms of timedelta since first studied,\n",
    "# and/or (3) by certain tags such as 'animal','verb' or 'commonword'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_it(sns.lmplot, x='factor', y='Syllables', data=df_binary2)\n",
    "\n",
    "def stuff_5():\n",
    "    ax = sns.lmplot(x='Syllables', y='factor', height=6, aspect=1.5, data=df_binary2, \n",
    "                    #fit_reg=False, #remove regression line\n",
    "                    #hue='ivl_q',\n",
    "                    legend_out = True\n",
    "                   )\n",
    "    ax.set(xlabel='Syllables', ylabel='Ease Factor')\n",
    "    #new_title = 'Interval Quintile'\n",
    "    #ax._legend.set_title(new_title)\n",
    "    plt.show()\n",
    "    \n",
    "time_it(stuff_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "time_it(sns.barplot, x='Syllables', y='factor', data=df_binary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "time_it(sns.violinplot, x='Syllables', y='factor', data=df_binary2)\n",
    "#time_it(sns.swarmplot, x='Syllables',\n",
    "#              y='factor',\n",
    "#              data=df_binary2, #make points black\n",
    "#              color=\"k\",\n",
    "#              alpha=0.5) #slightly transparent\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a histogram of the distribution of repetitions\n",
    "time_it(sns.distplot, df_binary2.reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a histogram of the distribution of ease\n",
    "time_it(sns.distplot, df_binary2.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a histogram of the distribution of intervals\n",
    "time_it(sns.distplot, df_binary2.ivl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary2.loc[df_binary2['Syllables']>18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a scatterplot\n",
    "time_it(sns.lmplot, x='factor', y='Syllables', data=df_binary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: increase in size, make sure data points are not obscured\n",
    "def stuff_a():\n",
    "    ax = sns.lmplot(x='reps', y='ivl', height=5, aspect=2, data=df_binary2, \n",
    "                    fit_reg=False, #remove regression line\n",
    "                    hue='ord',\n",
    "                    legend_out = True\n",
    "                   )\n",
    "    ax.set(xlabel='Card Reviews', ylabel='Ease Factor')\n",
    "    new_title = 'Card Vectors'\n",
    "    ax._legend.set_title(new_title)\n",
    "    plt.show()\n",
    "    \n",
    "time_it(stuff_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show correlation of stats via heatmap\n",
    "df_worked = df_binary2.copy() # 'ivl','factor','lapses'\n",
    "graph_drop_cols_1 = [\n",
    "    'nid','commonword','clothing','animal','body','food','textbook','college','place',\n",
    "    'fromdict','fromexam','onechar','n1','n2','n3','n4','n5','hasVisual',\n",
    "    'hasAudio','hasSimilar','hasAltForm','TermLen','Syllables','ivl_q']\n",
    "df_worked = df_worked.drop(graph_drop_cols_1,axis=1)\n",
    "corr = df_worked.corr()\n",
    "# https://stackoverflow.com/questions/38913965/make-the-size-of-a-heatmap-bigger-with-seaborn\n",
    "fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
    "sns.heatmap(corr, vmin=-1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric_non_binary = df_binary2.copy()\n",
    "graph_drop_cols_2 = [\n",
    "    'commonword','clothing','animal','body','food','textbook','college','place',\n",
    "    'fromdict','fromexam','onechar','n1','n2','n3','n4','n5','hasVisual',\n",
    "    'hasAudio','hasMultiMeaning','hasMultiReading','hasSimilar','hasHomophone',\n",
    "    'hasAltForm','tags','Term','Yomi1','Translation','PartOfSpeech','due','id',\n",
    "    'NoteCreated','nid','lapses','TermLen','Syllables']\n",
    "df_numeric_non_binary = df_numeric_non_binary.drop(graph_drop_cols_2,axis=1)\n",
    "#corr2 = df_hurt.corr()\n",
    "#fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
    "#sns.heatmap(corr2, vmin=-1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explore = df_binary2.copy()\n",
    "explore_drop = ['tags','Term','Yomi1','Translation','PartOfSpeech',\n",
    "                'ivl_q','n1','n2','n3','n4','n5','TermLenGroup','onechar',\n",
    "                'nid','id','due','NoteCreated','commonword','clothing','animal',\n",
    "                'body','food','place','textbook','college','fromdict','fromexam',\n",
    "                'hasVisual','hasAudio','hasMultiMeaning', 'hasMultiReading',\n",
    "                'hasSimilar', 'hasHomophone', 'hasAltForm'\n",
    "               ]\n",
    "df_explore = df_explore.drop(explore_drop,axis=1)\n",
    "df_explore.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
    "time_it(sns.violinplot, x=\"ord\", y=\"factor\", data=df_numeric_non_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
