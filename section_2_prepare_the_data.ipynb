{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab Analysis \n",
    "## Section 2: Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime, timedelta, date\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"datasets/collection.anki2\"\n",
    "cnx = sqlite3.connect(location) # create sql file connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDD backbone assertion to confirm a function call returns the desired result\n",
    "def assertEquals(actual, expected, desc):\n",
    "    assert(actual==expected), desc + \" result: \" + str(actual) + \", expected: \" + str(expected)\n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word anout how the data was stored\n",
    "\n",
    "Anki, the Open Source, Spaced Repetition software (& app & service), saves a student's data in a few locations. There are the \"Notes\" which are the raw info used to make cards (fields of vocab data, metatags, trivia facts, images, audio, etc..) Then there are the \"Cards\" which are the actual studied items, where the study overview data is stored (such as study date-times, repetitions (reviews), intervals (how long a card is to be remembered), lapses (forgets & subsequent interval resets)). Additionally, data concerning the entire collection is stored under something cryptically called \"Columns\". Lastly, there is a \"RevLog\" which contains all the study data in detail for each individual repetition (study datetime, card studied, etc..) This document was critical to piecing together the puzzle: https://github.com/ankidroid/Anki-Android/wiki/Database-Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract Deck Creation Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-08 09:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c = pd.read_sql_query(\"SELECT * FROM col\", cnx)\n",
    "crt = df_c['crt'][0] # save collection creation date (in epoch time)\n",
    "pd_crt = pd.to_datetime(crt, unit = 's')\n",
    "print(pd_crt)\n",
    "\n",
    "assertEquals(str(pd_crt), \"2013-01-08 09:00:00\", \"Collection Creation Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract field names to label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = []\n",
    "for row_index, blob in df_c['models'].items():\n",
    "    for model_id, data in json.loads(blob).items():\n",
    "        field_names += list(map(lambda fld: fld['name'], data['flds']))\n",
    "field_names.append('Tags')\n",
    "expected_names = ['Term', 'Yomi1', 'Translation', 'Translation2', 'Translation3', 'AlternateForms', 'PartOfSpeech', 'Sound', 'Sound2', 'Sound3', 'Examples', 'ExamplesAudio', 'AtoQ', 'AtoQaudio', 'AtoQkana', 'AtoQtranslation', 'QandApicture', 'answerPicture', 'Meaning1', 'SimilarWords', 'RelatedWords', 'Breakdown1', 'Comparison', 'Usage', 'Prompt1', 'Prompt2', 'KakuMCD', 'IuMCD', 'ExtraMemo', 'Yomi2', 'Meaning2', 'Breakdown2', 'Picture1', 'Picture2', 'Picture3', 'Picture4', 'HinshiMarker', 'Hint', 'Term2', 'ArabicNumeral', 'CounterKanji', 'Mnemonic', 'SameSoundWords', 'Yomi3', 'gChap', 'gBook', 'semester', 'gNumber', 'Transliteration', 'SoloLookCards', 'TagOverflow', 'blank1', 'blank2', 'Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(field_names, expected_names, \"Field Names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Import card data into data frame \"df_cards\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Take in study data from Anki collection\n",
    "df_cards = pd.read_sql_query(\"SELECT * FROM cards\", cnx)\n",
    "assertEquals(df_cards.shape[0],19314,\"Rows\")#6386, 21979, 19363\n",
    "assertEquals(df_cards.shape[1],18,\"Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Confirm that card data model matches expected format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_columns_1 = ['id', 'nid', 'did', 'ord', 'mod', 'usn', 'type', 'queue', 'due', 'ivl', 'factor',\n",
    " 'reps', 'lapses', 'left', 'odue', 'odid', 'flags', 'data']\n",
    "\n",
    "def lists_equal(a,b):\n",
    "    return (a == b).all()\n",
    "\n",
    "assertEquals(lists_equal(df_cards.columns.values, expected_columns_1), True, \"Card Columns Import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Shallow check for duplicates (matching rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    " def has_dupes(df_in):\n",
    "    dupe = df_in.duplicated()\n",
    "    return df_in.loc[dupe].shape[0] != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(has_dupes(df_cards), False, \"Duplicates Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Remove unneeded card dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_line_break():\n",
    "    print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_before_after(b, a, t=\"\"):\n",
    "    if t != \"\":\n",
    "        print_line_break()\n",
    "        print(t)\n",
    "    print_line_break()\n",
    "    print(\"Before: \" + str(b))\n",
    "    print_line_break()\n",
    "    print(\"After: \" + str(a))\n",
    "    print_line_break()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Card Columns:\n",
      "---------------------------------------------------------------------------\n",
      "Before: ['id' 'nid' 'did' 'ord' 'mod' 'usn' 'type' 'queue' 'due' 'ivl' 'factor'\n",
      " 'reps' 'lapses' 'left' 'odue' 'odid' 'flags' 'data']\n",
      "---------------------------------------------------------------------------\n",
      "After: ['id' 'nid' 'ord' 'queue' 'due' 'ivl' 'factor' 'reps' 'lapses']\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cards_001_less_cols = df_cards.copy()\n",
    "df_cards_001_less_cols = df_cards_001_less_cols.drop(['did','usn','type','mod','left','odue','odid','flags','data'],axis=1)\n",
    "expected_columns_2 = ['id', 'nid', 'ord', 'queue', 'due', 'ivl', 'factor', 'reps','lapses']\n",
    "\n",
    "print_before_after(df_cards.columns.values, df_cards_001_less_cols.columns.values,\"Card Columns:\")\n",
    "\n",
    "assertEquals(lists_equal(df_cards_001_less_cols.columns.values, expected_columns_2), True, \"Card Model Slimmed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Import notes (terms/words) into data frame \"df_notes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take in the 'notes' table, and explicitly save the note id (\"nid\") \n",
    "df_notes = pd.read_sql_query(\"SELECT * FROM notes\", cnx)\n",
    "df_notes = df_notes.rename(columns={'id':'nid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(df_notes.shape[0],8381,\"Rows\") # 2791, 9784, 8403\n",
    "assertEquals(df_notes.shape[1],11,\"Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Remove (drop) unneeded fields (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Before: ['nid' 'guid' 'mid' 'mod' 'usn' 'tags' 'flds' 'sfld' 'csum' 'flags' 'data']\n",
      "---------------------------------------------------------------------------\n",
      "After: ['nid' 'mod' 'tags' 'flds']\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_notes_old_col_vals = df_notes.columns.values\n",
    "df_notes = df_notes.drop(['guid','mid','usn','sfld','csum','flags','data'],axis=1)\n",
    "#print(df_notes.columns.values)\n",
    "print_before_after(df_notes_old_col_vals, df_notes.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Split \"fields\" column into multiple, assign field names, drop combined col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func, *args, **kwargs):\n",
    "    start = time.time()\n",
    "    func(*args, **kwargs)\n",
    "    end = time.time()\n",
    "    # https://stackoverflow.com/questions/8885663/how-to-format-a-floating-number-to-fixed-width-in-python\n",
    "    print(\"{:.0f}\".format((end - start)*1000) + \" miliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nid' 'mod' 'tags' 'Term' 'Yomi1' 'Translation' 'Translation2'\n",
      " 'Translation3' 'AlternateForms' 'PartOfSpeech' 'Sound' 'Sound2' 'Sound3'\n",
      " 'Examples' 'ExamplesAudio' 'AtoQ' 'AtoQaudio' 'AtoQkana'\n",
      " 'AtoQtranslation' 'QandApicture' 'answerPicture' 'Meaning1'\n",
      " 'SimilarWords' 'RelatedWords' 'Breakdown1' 'Comparison' 'Usage' 'Prompt1'\n",
      " 'Prompt2' 'KakuMCD' 'IuMCD' 'ExtraMemo' 'Yomi2' 'Meaning2' 'Breakdown2'\n",
      " 'Picture1' 'Picture2' 'Picture3' 'Picture4' 'HinshiMarker' 'Hint' 'Term2'\n",
      " 'ArabicNumeral' 'CounterKanji' 'Mnemonic' 'SameSoundWords' 'Yomi3'\n",
      " 'gChap' 'gBook' 'semester' 'gNumber' 'Transliteration' 'SoloLookCards'\n",
      " 'TagOverflow' 'blank1' 'blank2']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(expected_names)-1):\n",
    "    df_notes[expected_names[i]] = df_notes.flds.str.split('\u001f').str.get(i)\n",
    "assertEquals('flds' in df_notes.columns.values, True, \"'flds' Column Found\")\n",
    "df_notes = df_notes.drop(['flds'],axis=1)\n",
    "assertEquals('flds' not in df_notes.columns.values, True, \"'flds' Column Not Found\")\n",
    "print(df_notes.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure that all HTML tags have been removed from every card\n",
    "assertEquals(df_notes[df_notes['Term'].str.contains(\"</div>\")].shape[0],0,\"HTML tags have been removed\")\n",
    "assertEquals(df_notes[df_notes['Term'].str.contains(\"<div>\")].shape[0],0,\"HTML tags have been removed\")\n",
    "assertEquals(df_notes[df_notes['Term'].str.contains(\"anki\")].shape[0],0,\"HTML tags have been removed\")\n",
    "assertEquals(df_notes[df_notes['Yomi1'].str.contains(\"</span>\")].shape[0],0,\"HTML tags have been removed\")\n",
    "assertEquals(df_notes[df_notes['Yomi1'].str.contains(\"</div>\")].shape[0],0,\"HTML tags have been removed\")\n",
    "assertEquals(df_notes[df_notes['Yomi1'].str.contains(\"anki\")].shape[0],0,\"HTML tags have been removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: create function for this\n",
    "# inspect notes that have spaces in the reading field\n",
    "# df_notes[df_notes['Term'].str.contains(\" \")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Check notes for duplicates (shallow check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(has_dupes(df_notes), False, \"Duplicates Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Check for duplicates by term field in notes data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_dupe_terms(df_in):\n",
    "    location = df_in['Term'].duplicated()\n",
    "    return df_in.loc[location].shape[0] != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertEquals(has_dupe_terms(df_notes), False, \"Duplicates Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Confirm that duplicates dataframe is empty (no dups exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 56)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe = df_notes['Term'].duplicated() #creates list of True/False values\n",
    "print(df_notes[dupe].shape)\n",
    "assertEquals(df_notes[dupe].shape[0], 0, \"Duplicates dataframe is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Inspect an individual card by its term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postal service\n",
    "def inspect_note_by_term(df_in, term):\n",
    "    return df_in[df_in['Term']==term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>Yomi3</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>1361674609381</td>\n",
       "      <td>1555887839</td>\n",
       "      <td>Japanese Marked abaCheckNuance addDefinition ...</td>\n",
       "      <td>郵便</td>\n",
       "      <td>ゆうびん</td>\n",
       "      <td>mail, postal service</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>〒</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid         mod  \\\n",
       "3282  1361674609381  1555887839   \n",
       "\n",
       "                                                   tags Term Yomi1  \\\n",
       "3282   Japanese Marked abaCheckNuance addDefinition ...   郵便  ゆうびん   \n",
       "\n",
       "               Translation Translation2 Translation3 AlternateForms  \\\n",
       "3282  mail, postal service                                        〒   \n",
       "\n",
       "           PartOfSpeech  ...   Yomi3 gChap gBook semester gNumber  \\\n",
       "3282  Common word, Noun  ...                                        \n",
       "\n",
       "     Transliteration SoloLookCards TagOverflow blank1 blank2  \n",
       "3282                                                          \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel1 = inspect_note_by_term(df_notes,'郵便')\n",
    "sel1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Point, Commit, Bonfire (for you Souls fans)*\n",
    "\n",
    "At the point in time of the data extraction where the (meta) tag information is made available, we can treat it to both clarify (rename poorly worded tags) & reduce (delete unneeded tags). Since we now have all fields split into their own columns as well, we can treat (modifiy & improve) the columns as well, in a 1-2 process: (1) Fix the tags & (2) Fix the columns\n",
    "*https://en.wikipedia.org/wiki/Souls_(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_list(takeIn, takeOut):\n",
    "    temp = takeIn.lower().split() # split all the words into a list\n",
    "    temp2 = [word for word in temp if word.lower() not in takeOut] # create a shorter list of words minus the take-outs\n",
    "    return ' '.join(temp2) # return that shorter list as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_remove_list = ['japanese', 'checkpicture', 'complete', 'haspicture', 'nomemo',\n",
    "                   'researched', 'aaaeditthis', 'addaudio', 'addaudio2', 'addaudioNow',\n",
    "                   'addmore','adjustformatting', 'hascomparison', 'hasmnemonic',\n",
    "                   'customediting','wikidefinition', 'givewill','addaudionow','addprompt',\n",
    "                   'checknuance','giveyaneury','hastextimage', 'marked', 'addpicture',\n",
    "                   'addexampletranslation','basicnumeric', 'genkiplus', 'hasaudio',\n",
    "                   'nativeaudio', 'adddefinition','addexamples', 'addjapaneseprompt',\n",
    "                   'computervoice','haspoliteprefix','nongoo','customdefinition','hashint',\n",
    "                   'abahipriorityfix','kaki','mcd','nobodyknows+','missingwordtype',\n",
    "                   'image','duplicate', 'hasprompt', 'ninshiki','abachecknuance',\n",
    "                   'hasflag','things', 'jim', 'hasunicode', 'editthis','aaahipriority',\n",
    "                   'hassimpledef', 'givecodie', 'forjimmy', 'hasnativeaudio', 'givejimmy2',\n",
    "                   'checkaudio', 'checkwriting', 'hasjlptlevel', 'makekaki', 'checknuance2',\n",
    "                   'checkagain', 'newaudio', 'mail', 'checkexamples','elementaryschool',\n",
    "                   'nvc', 'checkprompt', 'gavejimmy', 'addnativeaudio','checkreading',\n",
    "                   'givecodieapril', 'activated', 'fixformatting','hasplacesuffix',\n",
    "                   'hassuffix','addtranslation','addnewcardtype','addnuance','addtextimage',\n",
    "                   'semicomplete', 'removeroboaudio','fixaudio','hasgramconj', \n",
    "                   'addkanji','changenotetype', 'famous', 'kuverb',\n",
    "                   'givwill','karutapoems', 'map', 'hasvisualcomparison','picturekaki',\n",
    "                   'jyugemu', '2018', 'type1', 'hasslang', 'apologies',\n",
    "                   'month', 'definitionresearched','soundshift', 'basics1', 'tsuverb',\n",
    "                   'facebook', 'uverb', 'checkfrequency', 'degree', 'hasdefinition',\n",
    "                   'addtransliteration', 'dnd', 'introductions', 'adjustprompt',\n",
    "                   'job', 'particle', 'services', 'mature', 'splitpictures', \n",
    "                   'egaki', 'type5k', 'intimate','extrainfo', 'irregular', 'unlisted',\n",
    "                   'fromwiki', 'checkdifference','addpronunciationdiagram', 'reset',\n",
    "                   'currentevents', 'doubletextimage', 'comparison', 'verbscompoundpast2',\n",
    "                   'attention', 'addmemo', 'averb', 'radio','hasascii', 'fontadjusted',\n",
    "                   'haspronunciation', 'borroweddefinition','alphabet', 'graphics',\n",
    "                   'chiebukuro', 'duolingo', 'ateji', 'fact','type5s', 'fixpicture',\n",
    "                   'politebydefault', 'objects','sensitive', 'groupword', 'addmnemonic',\n",
    "                   'hasmore', 'quote', 'checkformatting','overlap', 'kotobankdef',\n",
    "                   'hasrudeness', 'changedeck', 'specialformatting','yoga',\n",
    "                   'hasjapaneseprompt', 'hasprefix','questionword', 'business', \n",
    "                   'postoffice', 'firstten', 'money', 'robotvoice2', 'ichidan', 'godan',\n",
    "                   'weather','count', 'nodefinition', 'muverb', 'addcomparisonchart', \n",
    "                   'ruverb', 'phone', 'conjugated','haddiv','vulgar','fromkaruta',\n",
    "                   'karutamanual', 'teform', '2019'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Remove unneeded tags (meta-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>Yomi3</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797110</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>Japanese Marked abaCheckNuance checkNuance co...</td>\n",
       "      <td>臨機応変</td>\n",
       "      <td>りんきおうへん</td>\n",
       "      <td>adapting oneself to the requirements of the mo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun, No-adjective</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>Japanese complete noMemo researched wwwjdic</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797113</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>Japanese Marked abaCheckNuance checkNuance co...</td>\n",
       "      <td>苦汁</td>\n",
       "      <td>にがり</td>\n",
       "      <td>bittern; concentrated solution of salts (esp. ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod  \\\n",
       "0  1331799797110  1511481489   \n",
       "1  1331799797112  1511481489   \n",
       "2  1331799797113  1511481489   \n",
       "\n",
       "                                                tags  Term    Yomi1  \\\n",
       "0   Japanese Marked abaCheckNuance checkNuance co...  臨機応変  りんきおうへん   \n",
       "1       Japanese complete noMemo researched wwwjdic     隙間      すきま   \n",
       "2   Japanese Marked abaCheckNuance checkNuance co...    苦汁      にがり   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "0  adapting oneself to the requirements of the mo...                \n",
       "1            <div>crevice; crack; gap; opening</div>                \n",
       "2  bittern; concentrated solution of salts (esp. ...                \n",
       "\n",
       "  Translation3 AlternateForms                  PartOfSpeech  ...   Yomi3  \\\n",
       "0                                        Noun, No-adjective  ...           \n",
       "1                              <div>Common word, Noun</div>  ...           \n",
       "2                                                      Noun  ...           \n",
       "\n",
       "  gChap gBook semester gNumber Transliteration SoloLookCards TagOverflow  \\\n",
       "0                                                                          \n",
       "1                                                                          \n",
       "2                                                                          \n",
       "\n",
       "  blank1 blank2  \n",
       "0                \n",
       "1                \n",
       "2                \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# survey a few notes to see example tag data\n",
    "df_notes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Tags for 臨機応変\n",
      "---------------------------------------------------------------------------\n",
      "Before:  Japanese Marked abaCheckNuance checkNuance complete noMemo researched wwwjdic yojijukugo \n",
      "---------------------------------------------------------------------------\n",
      "After: wwwjdic yojijukugo\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likely useful tags: katakana, Waseigo, Food, Phrases, casual, restaurant, travel, commonWord, noun, suruVerb\n",
    "\n",
    "df_notes_001_less_tags = df_notes.copy() #originally \"df_notes_less_tags\"\n",
    "df_notes_001_less_tags['tags'] = df_notes_001_less_tags['tags'].apply(lambda x: shorten_list(str(x), tag_remove_list))\n",
    "\n",
    "print_before_after(df_notes['tags'].iloc[0], df_notes_001_less_tags['tags'].iloc[0],\"Tags for \" + df_notes['Term'].iloc[0])\n",
    "\n",
    "assertEquals(\"Japanese\" in df_notes['tags'].iloc[0].split(), True, \"Contains Tag 'Japanese'\")\n",
    "assertEquals(\"Japanese\" in df_notes_001_less_tags['tags'].iloc[0].split(), False, \"Contains Tag 'Japanese'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 17. Rename useful tags (meta-data) that were poorly named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace list (formerly named 'tag_replace_list')\n",
    "tag_rename_dict = {\n",
    "    'aalowfrequency':'rare checked', 'aatechnical':'technical checked', 'aaanonkaiwa':'nonconvo checked',\n",
    "    'wwwjdic':'fromdict', 'expression':'phrase', 'numberonly':'number',\n",
    "    'grammarpoint':'grammar', 'jisho':'fromdict', 'pointingword':'directions',\n",
    "    'geometry':'math technical', 'genki':'textbook', 'jpn202':'college',\n",
    "    'jpn201':'college', 'jpn101':'college', 'jpn102':'college', 'kentei':'fromexam',\n",
    "    'proficiencytest':'fromexam', 'bodypart':'body', '5kyuu':'fromexam',\n",
    "    'linguisticreference':'technical', 'conversation':'convo',\n",
    "    'fromconvo':'convo', 'culturepoint':'culture', 'checkednuance':'checked',\n",
    "    'checkedpictures':'checked', 'checkednuance':'checked', 'medical':'technical',\n",
    "    'anatomy':'body', 'places':'place', 'animals':'animal',\n",
    "    'newspaperterm':'fromnewspaper', 'checkedreading':'checked',\n",
    "    'abbreviation':'abbr','firstsemester':'semester1','onecharacter':'len1',\n",
    "    'sentence':'phrase', 'verbs':'verb', 'convook':'checked convo','inuse':'checked',\n",
    "    'nuancechecked':'checked','insects':'animal insect','sightseeing':'travel',\n",
    "    'accessories':'clothing', 'grammarsuffix':'suffix', 'oceanlife':'animal ocean',\n",
    "    'science':'technical', 'written':'nonconvo', 'notrare':'checked',\n",
    "    'aajoke':'silly', 'intonationcompare':'hassimilar', 'ij':'textbook',\n",
    "    'goodcard':'inspect','aahilevel':'challenging inspect', 'ijvocab':'textbook',\n",
    "    'cliothing':'clothing','unused':'nonconvo rare checked',\n",
    "    'aaunused':'nonconvo rare checked', 'samesound':'hassame','animals':'animal',\n",
    "    'dictionary':'fromdict','usuallywritteninkana':'kana',\n",
    "    'abVeryRare':'rare checked', 'yojijukugo':'rare idiom', 'abcasual':'casual checked convo',\n",
    "    'literaryform':'nonconvo', 'onomatopoeiclike':'onomatopoeic','kenjo':'humble',\n",
    "    'colors':'color', 'forest':'nature','flower':'plant nature', 'aaok':'checked',\n",
    "    'questions': 'question', 'adverbs':'adverb','book2':'textbook',\n",
    "    'book1':'textbook','proficiencytest':'fromtest','animalscomplete':'animal',\n",
    "    'sonkei':'respectful','eating':'food','fruit':'food','neverused':'nonconvo rare',\n",
    "    'domainspecific':'technical','seaons':'season','seasons':'season',\n",
    "    'prefecture':'place','plantpart':'plant', \"hakataben\":\"dialect\", \"fish\":\"animal fish\",\n",
    "    \"transitive\":\"transitive verb\", \"intransitive\":\"intransitive verb\",\n",
    "    \"aaunecessary\":\"nonconvo checked\", \"vegetables\":\"vegetable food plant\",\n",
    "    \"counters\":\"counter\", \"senmonyougo\":\"technical\", \"countries\":\"country place\",\n",
    "    \"date\":\"datesandtime\", \"rarelyused\":\"rare\", \"aaakaiwa\":\"convo checked\", \"cool\":\"inspect\",\n",
    "    \"investigate\":\"inspect\",\"challenging\":\"inspect\",\"names\":\"name\",'qanda':'question',\n",
    "    'hasquestion':'question', \"感情のもとにあったニーズ\":\"phrase rare\",\"phrases\":'phrase'\n",
    "}\n",
    "\n",
    "#todo: investigate:\n",
    "#editformatting,  datesandtime, linguistics, reference, adult, adjustpicture, checkpronunciation, addhint, challenging, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_list(takeIn, replaceDict):\n",
    "    temp = takeIn.lower().split()\n",
    "    temp2 = []\n",
    "    for word in temp:\n",
    "        if word in replaceDict:\n",
    "            temp2.append(replaceDict.get(word)) # if the word exists in the dictionary, replace it\n",
    "        else:\n",
    "            temp2.append(word) # if the word doesnt't exist in the dictionary, leave it alone\n",
    "    return ' '.join(temp2) # return that shorter list as a string\n",
    "\n",
    "# inspect further:\n",
    "# multiwriting, multimeaning, multipicture, multiterm, multireading, mergeterms, checkpronunciation, customterm,\n",
    "# goodcard, personalized, silly, addjlptlevel, checkpronunciation, mergeterms, customterm, transportation vs travel\n",
    "\n",
    "# categorize: iadjective, naajective, verb, counter, commonword, suruverb, pronoun, question, phrases, kuverb, godan, ichidan, intransitive, transitive, noun, adverbialnoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Tags for 臨機応変\n",
      "---------------------------------------------------------------------------\n",
      "Before: wwwjdic yojijukugo\n",
      "---------------------------------------------------------------------------\n",
      "After: fromdict rare idiom\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_002_better_tags = df_notes_001_less_tags.copy() # originally \"df_notes_better_tags\"\n",
    "df_notes_002_better_tags['tags'] = df_notes_002_better_tags['tags'].apply(lambda x: replace_list(str(x), tag_rename_dict))\n",
    "\n",
    "print_before_after(df_notes_001_less_tags['tags'].iloc[0], df_notes_002_better_tags['tags'].iloc[0], \"Tags for \" + df_notes_002_better_tags['Term'].iloc[0])\n",
    "\n",
    "assertEquals(\"wwwjdic\" in df_notes_001_less_tags['tags'].iloc[0].split(), True, \"Contains Tag 'wwwjdic'\")\n",
    "assertEquals(\"wwwjdic\" in df_notes_002_better_tags['tags'].iloc[0].split(), False, \"Contains Tag 'wwwjdic'\")\n",
    "assertEquals(\"fromdict\" in df_notes_001_less_tags['tags'].iloc[0].split(), False, \"Contains Tag 'fromdict'\")\n",
    "assertEquals(\"fromdict\" in df_notes_002_better_tags['tags'].iloc[0].split(), True, \"Contains Tag 'fromdict'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       1506\n",
       "fromdict                                778\n",
       "fromtest textbook                       582\n",
       "textbook textbook                       431\n",
       "college textbook textbook               241\n",
       "verb                                    199\n",
       "fromdict verb                           143\n",
       "fromexam                                116\n",
       "len1                                    107\n",
       "hiragana college textbook textbook      107\n",
       "hasrobo                                  99\n",
       "counter numeric                          96\n",
       "numeric                                  81\n",
       "addsimilar hasrobo                       73\n",
       "college textbook semester1 textbook      70\n",
       "fromdict media                           68\n",
       "fromexam textbook                        64\n",
       "fromdict lyrics                          62\n",
       "convo                                    57\n",
       "n3 fromdict transitive verb verb         56\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect tag strings, notice duplicate occurances of tags\n",
    "df_notes_002_better_tags['tags'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can attempt to inspect which tags are most common, in which combinations, and which words would be ideal\n",
    "for further additional metadata. However, **our tags are still lumped together** at this point. Also, there is\n",
    "reason to believe that **some tags are showing up multiple times in the same tag string**. In order to properly count tag frequency, the duplicates must be confirmed absent (ie. found & removed). Then, the occurance (word frequency) of each tag may then be summed up for the tags column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Inspect a note suspected for tag duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_note_by_id(df_in, nid):\n",
    "    return df_in[df_in['nid']==nid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that a particular note has tag duplicates\n",
    "# crimison note id: 1369286386384\n",
    "note_id_1 = 1369286386384\n",
    "assertEquals(inspect_note_by_id(df_notes_002_better_tags,note_id_1).tags.values[0],\n",
    "             \"fromexam color fromexam len1\",\"Four tags total with two duplicates exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>Yomi3</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>1369286386384</td>\n",
       "      <td>1511481489</td>\n",
       "      <td>fromexam color fromexam len1</td>\n",
       "      <td>紅</td>\n",
       "      <td>くれない</td>\n",
       "      <td>&lt;div&gt;deep red; crimson&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;&lt;div&gt;Common word, ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid         mod                          tags Term Yomi1  \\\n",
       "3845  1369286386384  1511481489  fromexam color fromexam len1    紅  くれない   \n",
       "\n",
       "                                            Translation Translation2  \\\n",
       "3845  <div>deep red; crimson</div><div><br /></div><...                \n",
       "\n",
       "     Translation3 AlternateForms  \\\n",
       "3845                               \n",
       "\n",
       "                                           PartOfSpeech  ...   Yomi3 gChap  \\\n",
       "3845  <div>Common word, Noun</div><div>Common word, ...  ...                 \n",
       "\n",
       "     gBook semester gNumber Transliteration SoloLookCards TagOverflow blank1  \\\n",
       "3845                                                                           \n",
       "\n",
       "     blank2  \n",
       "3845         \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of item with tag duplication\n",
    "sel2 = inspect_note_by_id(df_notes_002_better_tags,note_id_1)\n",
    "sel2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Remove duplicate tags (convert tag strings > lists > sets > strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a tag string to a list to a set back to a string (this removes the duplicates)\n",
    "def remove_dupes(t):\n",
    "    temp = list(set(t.lower().split()))\n",
    "    return ' '.join(temp) # return as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_003_tags_no_dups = df_notes_002_better_tags.copy()\n",
    "df_notes_003_tags_no_dups['tags'] = df_notes_003_tags_no_dups['tags'].apply(lambda x: remove_dupes(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if an individual tag substring exists in a larger tags list string\n",
    "def tag_exists(tags, tag):\n",
    "    return 1 if tag in tags.split() else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fromexam color len1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inspect_note_by_id(df_notes_003_tags_no_dups,note_id_1).tags.values[0])\n",
    "assertEquals(tag_exists(inspect_note_by_id(df_notes_003_tags_no_dups,note_id_1).tags.values[0],\"len1\"), 1, \"tag 'len1' remains\")\n",
    "assertEquals(tag_exists(inspect_note_by_id(df_notes_003_tags_no_dups,note_id_1).tags.values[0],\"fromexam\"), 1, \"tag 'fromexam' remains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we have most, if not all, of the data we need to start. The format of the dates though is not yet human readable. Let's fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Convert (& preserve) note ID to note creation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Term 臨機応変\n",
      "---------------------------------------------------------------------------\n",
      "Before: 1331799797110\n",
      "---------------------------------------------------------------------------\n",
      "After: 2012-03-15\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dueNum = 782 # this represents days from collection creation date\n",
    "#crt = 1357635600 # this represents the collection creation date #todo: query dynamically from database\n",
    "#print(\"mid 'model id': \" + time.ctime(int(\"1768161991\"))) # 1 day = 86400 seconds\n",
    "\n",
    "df_notes_004_with_date = df_notes_003_tags_no_dups.copy()\n",
    "df_notes_004_with_date['NoteCreated']= pd.to_datetime(df_notes_004_with_date['nid'],unit='ms')\n",
    "df_notes_004_with_date['NoteCreated'] = df_notes_004_with_date['NoteCreated'].dt.date\n",
    "df_notes_004_with_date.head()\n",
    "\n",
    "print_before_after(df_notes_003_tags_no_dups['nid'].iloc[0], df_notes_004_with_date['NoteCreated'].iloc[0],\"Term \" + df_notes_004_with_date['Term'].iloc[0])\n",
    "\n",
    "assertEquals(df_notes_004_with_date['nid'].iloc[0], 1331799797110, \"Note ID is in Epoch Units\")\n",
    "assertEquals(str(df_notes_004_with_date['NoteCreated'].iloc[0]), \"2012-03-15\", \"Note ID is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Generate Note Last Modified Date from \"Mod\" ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_005_last_modified = df_notes_004_with_date.copy()\n",
    "df_notes_005_last_modified['mod'] = pd.to_datetime(df_notes_005_last_modified['mod'],unit='s')\n",
    "df_notes_005_last_modified['mod'] = df_notes_005_last_modified['mod'].dt.date\n",
    "\n",
    "assertEquals(str(df_notes_005_last_modified['mod'].iloc[0]), \"2017-11-23\", \"Note last modified is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Remove rare words, phrases, expressions, questions & sentences from notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8381, 57)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "      <th>NoteCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797110</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict rare idiom</td>\n",
       "      <td>臨機応変</td>\n",
       "      <td>りんきおうへん</td>\n",
       "      <td>adapting oneself to the requirements of the mo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun, No-adjective</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797113</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>苦汁</td>\n",
       "      <td>にがり</td>\n",
       "      <td>bittern; concentrated solution of salts (esp. ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod                 tags  Term    Yomi1  \\\n",
       "0  1331799797110  2017-11-23  fromdict rare idiom  臨機応変  りんきおうへん   \n",
       "1  1331799797112  2017-11-23             fromdict    隙間      すきま   \n",
       "2  1331799797113  2017-11-23             fromdict    苦汁      にがり   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "0  adapting oneself to the requirements of the mo...                \n",
       "1            <div>crevice; crack; gap; opening</div>                \n",
       "2  bittern; concentrated solution of salts (esp. ...                \n",
       "\n",
       "  Translation3 AlternateForms                  PartOfSpeech     ...     gChap  \\\n",
       "0                                        Noun, No-adjective     ...             \n",
       "1                              <div>Common word, Noun</div>     ...             \n",
       "2                                                      Noun     ...             \n",
       "\n",
       "  gBook semester gNumber Transliteration SoloLookCards TagOverflow blank1  \\\n",
       "0                                                                           \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "\n",
       "  blank2 NoteCreated  \n",
       "0         2012-03-15  \n",
       "1         2012-03-15  \n",
       "2         2012-03-15  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_006_only_vocab_no_rare = df_notes_005_last_modified.copy()\n",
    "print(df_notes_006_only_vocab_no_rare.shape)\n",
    "df_notes_006_only_vocab_no_rare.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8269, 57)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "      <th>NoteCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797113</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>苦汁</td>\n",
       "      <td>にがり</td>\n",
       "      <td>bittern; concentrated solution of salts (esp. ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1331799797114</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>移籍</td>\n",
       "      <td>いせき</td>\n",
       "      <td>&lt;div&gt;changing household registry; transfer (e....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun, Suru verb&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod      tags Term Yomi1  \\\n",
       "1  1331799797112  2017-11-23  fromdict   隙間   すきま   \n",
       "2  1331799797113  2017-11-23  fromdict   苦汁   にがり   \n",
       "3  1331799797114  2017-11-23  fromdict   移籍   いせき   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "1            <div>crevice; crack; gap; opening</div>                \n",
       "2  bittern; concentrated solution of salts (esp. ...                \n",
       "3  <div>changing household registry; transfer (e....                \n",
       "\n",
       "  Translation3 AlternateForms                             PartOfSpeech  \\\n",
       "1                                         <div>Common word, Noun</div>   \n",
       "2                                                                 Noun   \n",
       "3                              <div>Common word, Noun, Suru verb</div>   \n",
       "\n",
       "      ...     gChap gBook semester gNumber Transliteration SoloLookCards  \\\n",
       "1     ...                                                                  \n",
       "2     ...                                                                  \n",
       "3     ...                                                                  \n",
       "\n",
       "  TagOverflow blank1 blank2 NoteCreated  \n",
       "1                            2012-03-15  \n",
       "2                            2012-03-15  \n",
       "3                            2012-03-15  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel4 = df_notes_006_only_vocab_no_rare[df_notes_006_only_vocab_no_rare['tags'].str.contains(\"rare\")]\n",
    "# https://stackoverflow.com/questions/37313691/how-to-remove-a-pandas-dataframe-from-another-dataframe\n",
    "# remove rare words only first\n",
    "df_notes_006_only_vocab_no_rare = pd.concat([df_notes_006_only_vocab_no_rare, sel4]).drop_duplicates(keep=False)\n",
    "\n",
    "print(df_notes_006_only_vocab_no_rare.shape)\n",
    "df_notes_006_only_vocab_no_rare.head(3)\n",
    "\n",
    "# todo: assert that no rare words remain in 'df_notes_006_only_vocab_no_rare' by using 'contain(\"rare\")'\n",
    "# for selection, assert that selection has a row size of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8048, 57)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>gChap</th>\n",
       "      <th>gBook</th>\n",
       "      <th>semester</th>\n",
       "      <th>gNumber</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>SoloLookCards</th>\n",
       "      <th>TagOverflow</th>\n",
       "      <th>blank1</th>\n",
       "      <th>blank2</th>\n",
       "      <th>NoteCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797113</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>苦汁</td>\n",
       "      <td>にがり</td>\n",
       "      <td>bittern; concentrated solution of salts (esp. ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1331799797114</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>移籍</td>\n",
       "      <td>いせき</td>\n",
       "      <td>&lt;div&gt;changing household registry; transfer (e....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun, Suru verb&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod      tags Term Yomi1  \\\n",
       "1  1331799797112  2017-11-23  fromdict   隙間   すきま   \n",
       "2  1331799797113  2017-11-23  fromdict   苦汁   にがり   \n",
       "3  1331799797114  2017-11-23  fromdict   移籍   いせき   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "1            <div>crevice; crack; gap; opening</div>                \n",
       "2  bittern; concentrated solution of salts (esp. ...                \n",
       "3  <div>changing household registry; transfer (e....                \n",
       "\n",
       "  Translation3 AlternateForms                             PartOfSpeech  \\\n",
       "1                                         <div>Common word, Noun</div>   \n",
       "2                                                                 Noun   \n",
       "3                              <div>Common word, Noun, Suru verb</div>   \n",
       "\n",
       "      ...     gChap gBook semester gNumber Transliteration SoloLookCards  \\\n",
       "1     ...                                                                  \n",
       "2     ...                                                                  \n",
       "3     ...                                                                  \n",
       "\n",
       "  TagOverflow blank1 blank2 NoteCreated  \n",
       "1                            2012-03-15  \n",
       "2                            2012-03-15  \n",
       "3                            2012-03-15  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove phrases, sentences & questions now all at once\n",
    "sel5 = df_notes_006_only_vocab_no_rare[df_notes_006_only_vocab_no_rare['tags'].str.contains(\"phrase\")]\n",
    "sel6 = df_notes_006_only_vocab_no_rare[df_notes_006_only_vocab_no_rare['tags'].str.contains(\"sentence\")]\n",
    "sel7 = df_notes_006_only_vocab_no_rare[df_notes_006_only_vocab_no_rare['tags'].str.contains(\"question\")]\n",
    "df_notes_006_only_vocab_no_rare = pd.concat([df_notes_006_only_vocab_no_rare, sel5, sel6, sel7]).drop_duplicates(keep=False)\n",
    "\n",
    "print(df_notes_006_only_vocab_no_rare.shape)\n",
    "df_notes_006_only_vocab_no_rare.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Create df_notes_midway data frame for progress saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_007_midway = df_notes_006_only_vocab_no_rare.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Export df_notes_midway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_007_midway.to_csv('datasets/notes_section_2_midway.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Generate Card Creation Date from Card ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cards_002_created_date = df_cards_001_less_cols.copy()\n",
    "df_cards_002_created_date['CardCreated'] = pd.to_datetime(df_cards_002_created_date['id'],unit='ms')\n",
    "df_cards_002_created_date['CardCreated'] = df_cards_002_created_date['CardCreated'].dt.date\n",
    "\n",
    "assertEquals(str(df_cards_002_created_date['CardCreated'].iloc[0]), \"2012-03-15\", \"Card ID is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Remove cards with no study data associated with them, cards that have been suspended from study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Card Rows:\n",
      "---------------------------------------------------------------------------\n",
      "Before: 19314\n",
      "---------------------------------------------------------------------------\n",
      "After: 8246\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nid</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>1549415185907</td>\n",
       "      <td>1549184119039</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2388</td>\n",
       "      <td>87</td>\n",
       "      <td>2410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>1550403009251</td>\n",
       "      <td>1550402953788</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2232</td>\n",
       "      <td>1</td>\n",
       "      <td>2410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>1550403009269</td>\n",
       "      <td>1550402953788</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2317</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>1550403084990</td>\n",
       "      <td>1550403040864</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2383</td>\n",
       "      <td>82</td>\n",
       "      <td>2410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>1550403085003</td>\n",
       "      <td>1550403040864</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2401</td>\n",
       "      <td>93</td>\n",
       "      <td>2410</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            nid  ord  queue   due  ivl  factor  reps  \\\n",
       "18898  1549415185907  1549184119039    2      2  2388   87    2410     3   \n",
       "18899  1550403009251  1550402953788    0     -2  2232    1    2410     3   \n",
       "18900  1550403009269  1550402953788    2      2  2317    9    2010     9   \n",
       "18901  1550403084990  1550403040864    0      2  2383   82    2410     3   \n",
       "18902  1550403085003  1550403040864    2      2  2401   93    2410     4   \n",
       "\n",
       "       lapses CardCreated  \n",
       "18898       0  2019-02-06  \n",
       "18899       0  2019-02-17  \n",
       "18900       2  2019-02-17  \n",
       "18901       0  2019-02-17  \n",
       "18902       0  2019-02-17  "
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#queue           integer not null,\n",
    "#      -- -3=sched buried, -2=user buried, -1=suspended,\n",
    "#      -- 0=new, 1=learning, 2=due (as for type)\n",
    "\n",
    "df_cards_003_no_new = df_cards_002_created_date.copy()\n",
    "df_cards_003_no_new = df_cards_003_no_new[df_cards_003_no_new['queue']!=0] # remove cards marked as new\n",
    "df_cards_003_no_new = df_cards_003_no_new[df_cards_003_no_new['reps']!=0] # remove cards that have not been reviewed\n",
    "df_cards_003_no_new = df_cards_003_no_new[df_cards_003_no_new['queue']!=-1] # remove cards that are currently suspended\n",
    "# https://stackoverflow.com/questions/18196203/how-to-conditionally-update-dataframe-column-in-pandas\n",
    "df_cards_003_no_new.loc[df_cards_003_no_new['due'] > 10000, 'due'] = 0 # assign 0 to the due # todo: update w/ last studied date from revlog # todo: comment this line out once you have updated the collection import\n",
    "\n",
    "print_before_after(df_cards_002_created_date.shape[0], df_cards_003_no_new.shape[0],\"Card Rows:\")\n",
    "\n",
    "df_cards_003_no_new.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Confirm that no cards considered 'in learning' are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel3 = df_cards_003_no_new[df_cards_003_no_new['due'] == 0]\n",
    "\n",
    "assertEquals(sel3.shape[0],0,\"There are no cards currently in 'learning'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. Generate Due Date from Due Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cards_004_due_date = df_cards_003_no_new.copy()\n",
    "df_cards_004_due_date['due'] = pd_crt + df_cards_004_due_date['due'].map(timedelta)\n",
    "df_cards_004_due_date['due'] = df_cards_004_due_date['due'].dt.date\n",
    "\n",
    "assertEquals(str(df_cards_004_due_date['due'].iloc[0]), \"2015-03-08\", \"Card due date is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. Create df_cards_final data frame for export & further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards_final = df_cards_004_due_date.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. Export df_cards_section_2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards_final.to_csv('datasets/cards_section_2_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31. Merge card & note data frames to conduct cross analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7957, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797112</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>149</td>\n",
       "      <td>2080</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797114</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>移籍</td>\n",
       "      <td>いせき</td>\n",
       "      <td>&lt;div&gt;changing household registry; transfer (e....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun, Suru verb&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797114</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>99</td>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797117</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict verb</td>\n",
       "      <td>吊るす</td>\n",
       "      <td>つるす</td>\n",
       "      <td>to hang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>143</td>\n",
       "      <td>2130</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1331799797118</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict convo checked</td>\n",
       "      <td>和やか</td>\n",
       "      <td>なごやか</td>\n",
       "      <td>harmonious, peaceful</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797118</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-06</td>\n",
       "      <td>74</td>\n",
       "      <td>1880</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1331799797121</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>営業日</td>\n",
       "      <td>えいぎょうび</td>\n",
       "      <td>business day</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>1331799797121</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>132</td>\n",
       "      <td>2130</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod                    tags Term   Yomi1  \\\n",
       "0  1331799797112  2017-11-23                fromdict   隙間     すきま   \n",
       "1  1331799797114  2017-11-23                fromdict   移籍     いせき   \n",
       "2  1331799797117  2017-11-23           fromdict verb  吊るす     つるす   \n",
       "3  1331799797118  2017-11-23  fromdict convo checked  和やか    なごやか   \n",
       "4  1331799797121  2017-11-23                fromdict  営業日  えいぎょうび   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "0            <div>crevice; crack; gap; opening</div>                \n",
       "1  <div>changing household registry; transfer (e....                \n",
       "2                                            to hang                \n",
       "3                               harmonious, peaceful                \n",
       "4                                       business day                \n",
       "\n",
       "  Translation3 AlternateForms                             PartOfSpeech  \\\n",
       "0                                         <div>Common word, Noun</div>   \n",
       "1                              <div>Common word, Noun, Suru verb</div>   \n",
       "2                                                                        \n",
       "3                                                                        \n",
       "4                                                                        \n",
       "\n",
       "      ...     NoteCreated             id ord queue         due  ivl factor  \\\n",
       "0     ...      2012-03-15  1331799797112   0     2  2015-03-03  149   2080   \n",
       "1     ...      2012-03-15  1331799797114   0     2  2015-02-04   99   1980   \n",
       "2     ...      2012-03-15  1331799797117   0     2  2015-03-17  143   2130   \n",
       "3     ...      2012-03-15  1331799797118   0     2  2015-02-06   74   1880   \n",
       "4     ...      2012-03-15  1331799797121   0     2  2015-03-03  132   2130   \n",
       "\n",
       "  reps lapses CardCreated  \n",
       "0    8      1  2012-03-15  \n",
       "1    7      0  2012-03-15  \n",
       "2    6      1  2012-03-15  \n",
       "3   15      3  2012-03-15  \n",
       "4    6      1  2012-03-15  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that we have note id's for all the words, we can\n",
    "# join together these separate dataframes\n",
    "df_combo = pd.merge(df_notes_007_midway, df_cards_final, on='nid')\n",
    "print(df_combo.shape)\n",
    "df_combo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The card model has a bunch of columns (fields) with no values in them. These can be taken out for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blank (s):\n",
    "    return not (s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_of_cards_by_term(df, t):\n",
    "    return df.loc[df['Term']==t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>1354094556789</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>fromtest suruverb commonword noun n3 textbook</td>\n",
       "      <td>発明</td>\n",
       "      <td>はつめい</td>\n",
       "      <td>&lt;span style=\"\"&gt;&lt;div&gt;invention&lt;/div&gt;&lt;/span&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Common word, Noun, Suru verb</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>1354094556789</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>80</td>\n",
       "      <td>1300</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>1354094556789</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>fromtest suruverb commonword noun n3 textbook</td>\n",
       "      <td>発明</td>\n",
       "      <td>はつめい</td>\n",
       "      <td>&lt;span style=\"\"&gt;&lt;div&gt;invention&lt;/div&gt;&lt;/span&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Common word, Noun, Suru verb</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>1371807076626</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>1056</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid         mod  \\\n",
       "2799  1354094556789  2018-12-03   \n",
       "2800  1354094556789  2018-12-03   \n",
       "\n",
       "                                               tags Term Yomi1  \\\n",
       "2799  fromtest suruverb commonword noun n3 textbook   発明  はつめい   \n",
       "2800  fromtest suruverb commonword noun n3 textbook   発明  はつめい   \n",
       "\n",
       "                                     Translation Translation2 Translation3  \\\n",
       "2799  <span style=\"\"><div>invention</div></span>                             \n",
       "2800  <span style=\"\"><div>invention</div></span>                             \n",
       "\n",
       "     AlternateForms                  PartOfSpeech     ...     NoteCreated  \\\n",
       "2799                 Common word, Noun, Suru verb     ...      2012-11-28   \n",
       "2800                 Common word, Noun, Suru verb     ...      2012-11-28   \n",
       "\n",
       "                 id ord queue         due   ivl factor reps lapses CardCreated  \n",
       "2799  1354094556789   0     2  2015-06-30    80   1300   73      9  2012-11-28  \n",
       "2800  1371807076626   4     2  2021-10-24  1056   1300   20      0  2013-06-21  \n",
       "\n",
       "[2 rows x 66 columns]"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look a a small slice of data, to infer what we may\n",
    "# we can take a broad overview look at the dataset to more quickly isolate candidates for removal\n",
    "s = get_frame_of_cards_by_term(df_combo, '発明')\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Determine which columns (fields) are unused & can be safely removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal candidates: ['Sound3', 'AtoQ', 'AtoQaudio', 'AtoQkana', 'AtoQtranslation', 'QandApicture', 'answerPicture', 'blank1', 'blank2']\n"
     ]
    }
   ],
   "source": [
    "col_names = df_combo.columns.values\n",
    "#print(is_blank(df_combo['Translation2'].iloc[0])) # see that this cell for this row is indeed blank\n",
    "\n",
    "row_cnt = df_combo.shape[0] # number of rows in df_combo\n",
    "\n",
    "# https://stackoverflow.com/questions/49677060/pandas-count-empty-strings-in-a-column\n",
    "empty_strings = pd.DataFrame(df_combo.values == '',columns=col_names) # find all empty strings in a DataFrame\n",
    "temp_dict = (empty_strings.sum()).to_dict()  # save the location of all empty strings as a DataFrame of booleans\n",
    "removal_candidates = []\n",
    "for key in temp_dict.items():\n",
    "    if key[1] == row_cnt:\n",
    "        removal_candidates.append(key[0])\n",
    "print(\"Removal candidates:\", removal_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Trim unneeded (empty) columns from combo data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Before: (7957, 66)\n",
      "---------------------------------------------------------------------------\n",
      "After: (7957, 56)\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "Before: ['nid' 'mod' 'tags' 'Term' 'Yomi1' 'Translation' 'Translation2'\n",
      " 'Translation3' 'AlternateForms' 'PartOfSpeech' 'Sound' 'Sound2' 'Sound3'\n",
      " 'Examples' 'ExamplesAudio' 'AtoQ' 'AtoQaudio' 'AtoQkana'\n",
      " 'AtoQtranslation' 'QandApicture' 'answerPicture' 'Meaning1'\n",
      " 'SimilarWords' 'RelatedWords' 'Breakdown1' 'Comparison' 'Usage' 'Prompt1'\n",
      " 'Prompt2' 'KakuMCD' 'IuMCD' 'ExtraMemo' 'Yomi2' 'Meaning2' 'Breakdown2'\n",
      " 'Picture1' 'Picture2' 'Picture3' 'Picture4' 'HinshiMarker' 'Hint' 'Term2'\n",
      " 'ArabicNumeral' 'CounterKanji' 'Mnemonic' 'SameSoundWords' 'Yomi3'\n",
      " 'gChap' 'gBook' 'semester' 'gNumber' 'Transliteration' 'SoloLookCards'\n",
      " 'TagOverflow' 'blank1' 'blank2' 'NoteCreated' 'id' 'ord' 'queue' 'due'\n",
      " 'ivl' 'factor' 'reps' 'lapses' 'CardCreated']\n",
      "---------------------------------------------------------------------------\n",
      "After: ['nid' 'mod' 'tags' 'Term' 'Yomi1' 'Translation' 'Translation2'\n",
      " 'Translation3' 'AlternateForms' 'PartOfSpeech' 'Sound' 'Sound2'\n",
      " 'Examples' 'ExamplesAudio' 'Meaning1' 'SimilarWords' 'RelatedWords'\n",
      " 'Breakdown1' 'Comparison' 'Usage' 'Prompt1' 'Prompt2' 'KakuMCD' 'IuMCD'\n",
      " 'ExtraMemo' 'Yomi2' 'Meaning2' 'Breakdown2' 'Picture1' 'Picture2'\n",
      " 'Picture3' 'Picture4' 'HinshiMarker' 'Hint' 'Term2' 'ArabicNumeral'\n",
      " 'CounterKanji' 'Mnemonic' 'SameSoundWords' 'Yomi3' 'gChap' 'gBook'\n",
      " 'semester' 'gNumber' 'Transliteration' 'SoloLookCards' 'TagOverflow'\n",
      " 'NoteCreated' 'id' 'ord' 'due' 'ivl' 'factor' 'reps' 'lapses'\n",
      " 'CardCreated']\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_combo_001_less_cols = df_combo.copy()\n",
    "\n",
    "removal_list = list(removal_candidates + ['queue'])\n",
    "\n",
    "df_combo_001_less_cols = df_combo_001_less_cols.drop(removal_list,axis=1)\n",
    "\n",
    "print_before_after(df_combo.shape, df_combo_001_less_cols.shape)\n",
    "print_before_after(df_combo.columns.values, df_combo_001_less_cols.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that card types are being rendered as numbers, which makes it less human readible. We will fix this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. Label card types by their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     6574\n",
      "4     1100\n",
      "7      269\n",
      "2       13\n",
      "11       1\n",
      "Name: ord, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "read      6574\n",
       "look      1100\n",
       "listen     269\n",
       "recall      13\n",
       "Name: CardType, dtype: int64"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ord stands for 'ordinal' : identifies which of the card templates it corresponds to\n",
    "print(df_combo_001_less_cols['ord'].value_counts()) # these are the card vectors\n",
    "\n",
    "# since our dataset contains a single card of a single card vector, & the card vectors\n",
    "# aren't named/labeled, let's remove the outlier & add the names\n",
    "df_combo_002_types_labeled = df_combo_001_less_cols.copy()\n",
    "df_combo_002_types_labeled = df_combo_002_types_labeled.drop(df_combo_002_types_labeled[df_combo_002_types_labeled['ord'] == 11].index)\n",
    "\n",
    "df_combo_002_types_labeled['ord'].value_counts() # the check shall pass\n",
    "\n",
    "# now, to map the names onto the card vectors # read:JapaneseReading, recall:EngToJpnTranslate, look:PictureLook, listen:AudioListening\n",
    "df_combo_002_types_labeled['CardType'] = df_combo_002_types_labeled['ord'].map({0:'read', 2:'recall',4:'look',7:'listen'})\n",
    "df_combo_002_types_labeled['CardType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. Create binary exists/not columns based on presence of a given tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_by_tag(df, tag):\n",
    "    df[tag] = df['tags'].apply(lambda x: tag_exists(str(x), tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_003_with_binary = df_combo_002_types_labeled.copy()\n",
    "inspect_list = [\"commonword\", \"clothing\", \"animal\", \"body\", \"food\", \"place\",\n",
    "                \"textbook\", \"college\", \"fromdict\", \"fromexam\",\n",
    "                \"len1\", \"n1\", \"n2\", \"n3\", \"n4\", \"n5\", 'katakana','hiragana',\n",
    "                'noun', 'verb', 'convo'\n",
    "               ]\n",
    "for item in inspect_list:\n",
    "    add_column_by_tag(df_combo_003_with_binary, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    50\n",
       "int64     28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_003_with_binary.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. Create interval quartile sections for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>mod</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Translation2</th>\n",
       "      <th>Translation3</th>\n",
       "      <th>AlternateForms</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>...</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>katakana</th>\n",
       "      <th>hiragana</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>convo</th>\n",
       "      <th>ivl_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797112</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>隙間</td>\n",
       "      <td>すきま</td>\n",
       "      <td>&lt;div&gt;crevice; crack; gap; opening&lt;/div&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331799797114</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>移籍</td>\n",
       "      <td>いせき</td>\n",
       "      <td>&lt;div&gt;changing household registry; transfer (e....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;Common word, Noun, Suru verb&lt;/div&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1331799797117</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict verb</td>\n",
       "      <td>吊るす</td>\n",
       "      <td>つるす</td>\n",
       "      <td>to hang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1331799797118</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict convo checked</td>\n",
       "      <td>和やか</td>\n",
       "      <td>なごやか</td>\n",
       "      <td>harmonious, peaceful</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1331799797121</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>営業日</td>\n",
       "      <td>えいぎょうび</td>\n",
       "      <td>business day</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             nid         mod                    tags Term   Yomi1  \\\n",
       "0  1331799797112  2017-11-23                fromdict   隙間     すきま   \n",
       "1  1331799797114  2017-11-23                fromdict   移籍     いせき   \n",
       "2  1331799797117  2017-11-23           fromdict verb  吊るす     つるす   \n",
       "3  1331799797118  2017-11-23  fromdict convo checked  和やか    なごやか   \n",
       "4  1331799797121  2017-11-23                fromdict  営業日  えいぎょうび   \n",
       "\n",
       "                                         Translation Translation2  \\\n",
       "0            <div>crevice; crack; gap; opening</div>                \n",
       "1  <div>changing household registry; transfer (e....                \n",
       "2                                            to hang                \n",
       "3                               harmonious, peaceful                \n",
       "4                                       business day                \n",
       "\n",
       "  Translation3 AlternateForms                             PartOfSpeech  ...   \\\n",
       "0                                         <div>Common word, Noun</div>  ...    \n",
       "1                              <div>Common word, Noun, Suru verb</div>  ...    \n",
       "2                                                                       ...    \n",
       "3                                                                       ...    \n",
       "4                                                                       ...    \n",
       "\n",
       "  n2 n3 n4 n5 katakana hiragana noun verb convo ivl_q  \n",
       "0  0  0  0  0        0        0    0    0     0     1  \n",
       "1  0  0  0  0        0        0    0    0     0     0  \n",
       "2  0  0  0  0        0        0    0    1     0     0  \n",
       "3  0  0  0  0        0        0    0    0     1     0  \n",
       "4  0  0  0  0        0        0    0    0     0     0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qcut: Quantile-based discretization function. Discretize variable into equal-sized buckets\n",
    "# based on rank or based on sample quantiles. For example 1000 values for 10 quantiles would\n",
    "# produce a Categorical object indicating quantile membership for each data point.\n",
    "# http://www.datasciencemadesimple.com/quantile-decile-rank-column-pandas-python-2/\n",
    "df_combo_003_with_binary['ivl_q'] = pd.qcut(df_combo_003_with_binary['ivl'],5,labels=False)\n",
    "df_combo_003_with_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further refine the dataframe entries to represent which notes have (1) visual data, (2) audio data, and (3) a L1 (\"first language\", English in this case) translation. We can represent these with binary values (0 for doesn't exist, 1 for exists)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. Create boolean columns for predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura calls this process \"Data Enriching\"\n",
    "intify_list = ['hasPOS','hasVisual','hasAudio','hasMultiMeaning','hasMultiReading','hasSimilar','hasHomophone','hasAltForm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/17383094/how-can-i-map-true-false-to-1-0-in-a-pandas-dataframe\n",
    "df_combo_003_with_binary['hasPOS'] = df_combo_003_with_binary['PartOfSpeech']!=\"\" #todo: expand upon this, by tagify\n",
    "df_combo_003_with_binary['hasVisual'] = df_combo_003_with_binary['Picture1']!=\"\"\n",
    "df_combo_003_with_binary['hasAudio'] = df_combo_003_with_binary['Sound']!=\"\"\n",
    "df_combo_003_with_binary['hasMultiMeaning'] = df_combo_003_with_binary['Translation2' and 'Translation3' and 'Meaning2']!=\"\"\n",
    "df_combo_003_with_binary['hasMultiReading'] = df_combo_003_with_binary['Yomi2']!=\"\" # todo: inspect & incorporate venn diagram: https://commons.wikimedia.org/wiki/File:Homograph_homophone_venn_diagram.png\n",
    "df_combo_003_with_binary['hasSimilar'] = df_combo_003_with_binary['SimilarWords']!=\"\"\n",
    "df_combo_003_with_binary['hasHomophone'] = df_combo_003_with_binary['SameSoundWords']!=\"\" # write function, detect homophones\n",
    "df_combo_003_with_binary['hasAltForm'] = df_combo_003_with_binary['Term2' and 'AlternateForms']!= \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. Drop non-numerical columns from combo data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_004_less_cols = df_combo_003_with_binary.copy()\n",
    "df_combo_004_less_cols = df_combo_004_less_cols.drop(['Examples','ExamplesAudio',\n",
    "                            'Meaning1','RelatedWords','Breakdown1','Comparison',\n",
    "                           'Usage','Prompt1','Prompt2','KakuMCD','IuMCD','ExtraMemo',\n",
    "                           'Breakdown2','Picture2','Picture3','Picture4','Mnemonic',\n",
    "                            'Yomi3','gChap','gBook','semester','gNumber','ArabicNumeral',\n",
    "                            'CounterKanji','SoloLookCards','HinshiMarker','Hint',\n",
    "                            'mod','Transliteration'],axis=1)\n",
    "# todo: explore 'mod' (last modified date) as freshness metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casts columns of type object to type int as directed, use with caution\n",
    "def intify_bools(df, col):\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. Ensure numerical/boolean types are encoded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     29\n",
       "object    21\n",
       "bool       8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_004_less_cols.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in intify_list:\n",
    "    intify_bools(df_combo_004_less_cols,item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     37\n",
       "object    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_004_less_cols.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. Further reduce columns no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>due</th>\n",
       "      <th>...</th>\n",
       "      <th>verb</th>\n",
       "      <th>convo</th>\n",
       "      <th>ivl_q</th>\n",
       "      <th>hasVisual</th>\n",
       "      <th>hasAudio</th>\n",
       "      <th>hasMultiMeaning</th>\n",
       "      <th>hasMultiReading</th>\n",
       "      <th>hasSimilar</th>\n",
       "      <th>hasHomophone</th>\n",
       "      <th>hasAltForm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1342506824725</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>事情</td>\n",
       "      <td>じじょう</td>\n",
       "      <td>circumstances; consideration; conditions; situ...</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824725</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1342506824726</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>事柄</td>\n",
       "      <td>ことがら</td>\n",
       "      <td>matter; thing; affair; circumstance</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824726</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1342506824727</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>物事</td>\n",
       "      <td>ものごと</td>\n",
       "      <td>things; everything</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824727</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1342506824728</td>\n",
       "      <td>fromtest fromdict textbook</td>\n",
       "      <td>方法</td>\n",
       "      <td>ほうほう</td>\n",
       "      <td>&lt;span style=\" font-style: normal; font-weight:...</td>\n",
       "      <td></td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824728</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1342506824729</td>\n",
       "      <td>fromdict</td>\n",
       "      <td>行為</td>\n",
       "      <td>こうい</td>\n",
       "      <td>act, deed, conduct</td>\n",
       "      <td>Common word, Noun</td>\n",
       "      <td>2012-07-17</td>\n",
       "      <td>1342506824729</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nid                        tags Term Yomi1  \\\n",
       "30  1342506824725                    fromdict   事情  じじょう   \n",
       "31  1342506824726                    fromdict   事柄  ことがら   \n",
       "32  1342506824727                    fromdict   物事  ものごと   \n",
       "33  1342506824728  fromtest fromdict textbook   方法  ほうほう   \n",
       "34  1342506824729                    fromdict   行為   こうい   \n",
       "\n",
       "                                          Translation       PartOfSpeech  \\\n",
       "30  circumstances; consideration; conditions; situ...  Common word, Noun   \n",
       "31                matter; thing; affair; circumstance  Common word, Noun   \n",
       "32                                things; everything   Common word, Noun   \n",
       "33  <span style=\" font-style: normal; font-weight:...                      \n",
       "34                                 act, deed, conduct  Common word, Noun   \n",
       "\n",
       "   NoteCreated             id  ord         due     ...      verb  convo  \\\n",
       "30  2012-07-17  1342506824725    0  2015-07-10     ...         0      0   \n",
       "31  2012-07-17  1342506824726    0  2015-11-10     ...         0      0   \n",
       "32  2012-07-17  1342506824727    0  2016-03-17     ...         0      0   \n",
       "33  2012-07-17  1342506824728    0  2015-10-24     ...         0      0   \n",
       "34  2012-07-17  1342506824729    0  2015-04-16     ...         0      0   \n",
       "\n",
       "    ivl_q  hasVisual hasAudio hasMultiMeaning  hasMultiReading  hasSimilar  \\\n",
       "30      2          0        0               0                0           0   \n",
       "31      2          0        0               0                0           1   \n",
       "32      2          0        0               0                0           1   \n",
       "33      3          0        0               0                0           0   \n",
       "34      0          0        0               0                0           1   \n",
       "\n",
       "    hasHomophone  hasAltForm  \n",
       "30             0           0  \n",
       "31             0           0  \n",
       "32             0           0  \n",
       "33             0           0  \n",
       "34             0           0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_004_less_cols = df_combo_004_less_cols.drop(['Picture1','Sound','Sound2',\n",
    "                              'TagOverflow','Translation2', 'Meaning2','Yomi2','Term2',\n",
    "                              'SameSoundWords','hasPOS','SimilarWords','AlternateForms',\n",
    "                            'Translation3'],axis=1)\n",
    "df_combo_004_less_cols.head(35)[30:]\n",
    "\n",
    "#selection2 = df_binary.loc[df_binary['hasMultiMeaning']==1]\n",
    "#selection2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. Count syllable count & character length for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>due</th>\n",
       "      <th>...</th>\n",
       "      <th>hasVisual</th>\n",
       "      <th>hasAudio</th>\n",
       "      <th>hasMultiMeaning</th>\n",
       "      <th>hasMultiReading</th>\n",
       "      <th>hasSimilar</th>\n",
       "      <th>hasHomophone</th>\n",
       "      <th>hasAltForm</th>\n",
       "      <th>TermLen</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>TermLenGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>1483483651002</td>\n",
       "      <td>clothing college gairaigo katakana textbook</td>\n",
       "      <td>ネクタイ</td>\n",
       "      <td></td>\n",
       "      <td>necktie</td>\n",
       "      <td></td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>1485707813168</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>1483483651027</td>\n",
       "      <td>clothing college gairaigo katakana textbook</td>\n",
       "      <td>ジャケット</td>\n",
       "      <td></td>\n",
       "      <td>jacket</td>\n",
       "      <td></td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>1485708017322</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>1485703825555</td>\n",
       "      <td>clothing gairaigo katakana n5 commonword noun ...</td>\n",
       "      <td>ズボン</td>\n",
       "      <td></td>\n",
       "      <td>1. trousers; pants</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>1485708950599</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>1485705402623</td>\n",
       "      <td>clothing gairaigo katakana commonword noun</td>\n",
       "      <td>ブラジャー</td>\n",
       "      <td></td>\n",
       "      <td>1. bra; brassiere</td>\n",
       "      <td></td>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>1485707774754</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7941</th>\n",
       "      <td>1489373157595</td>\n",
       "      <td></td>\n",
       "      <td>細切り</td>\n",
       "      <td>ほそぎり</td>\n",
       "      <td>thin strips; matchstick-like strips; julienned...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>1489373228966</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[3:4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid                                               tags   Term  \\\n",
       "7937  1483483651002        clothing college gairaigo katakana textbook   ネクタイ   \n",
       "7938  1483483651027        clothing college gairaigo katakana textbook  ジャケット   \n",
       "7939  1485703825555  clothing gairaigo katakana n5 commonword noun ...    ズボン   \n",
       "7940  1485705402623         clothing gairaigo katakana commonword noun  ブラジャー   \n",
       "7941  1489373157595                                                       細切り   \n",
       "\n",
       "     Yomi1                                        Translation PartOfSpeech  \\\n",
       "7937                                                  necktie                \n",
       "7938                                                   jacket                \n",
       "7939                                       1. trousers; pants         Noun   \n",
       "7940                                        1. bra; brassiere                \n",
       "7941  ほそぎり  thin strips; matchstick-like strips; julienned...         Noun   \n",
       "\n",
       "     NoteCreated             id  ord         due      ...       hasVisual  \\\n",
       "7937  2017-01-03  1485707813168    4  2020-03-29      ...               1   \n",
       "7938  2017-01-03  1485708017322    4  2020-09-27      ...               1   \n",
       "7939  2017-01-29  1485708950599    4  2020-06-11      ...               1   \n",
       "7940  2017-01-29  1485707774754    4  2019-05-02      ...               1   \n",
       "7941  2017-03-13  1489373228966    0  2017-03-25      ...               0   \n",
       "\n",
       "      hasAudio  hasMultiMeaning  hasMultiReading hasSimilar hasHomophone  \\\n",
       "7937         1                0                0          0            0   \n",
       "7938         1                0                0          0            0   \n",
       "7939         1                0                0          0            0   \n",
       "7940         0                0                0          0            0   \n",
       "7941         0                0                0          0            0   \n",
       "\n",
       "      hasAltForm  TermLen  Syllables  TermLenGroup  \n",
       "7937           0        4          4         [3:4]  \n",
       "7938           0        5          5         [5:8]  \n",
       "7939           0        3          3         [3:4]  \n",
       "7940           0        5          5         [5:8]  \n",
       "7941           0        3          4         [3:4]  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_005_with_len = df_combo_004_less_cols.copy()\n",
    "\n",
    "df_combo_005_with_len['TermLen'] = df_combo_005_with_len['Term'].str.len()\n",
    "df_combo_005_with_len['Syllables'] = df_combo_005_with_len['Yomi1'].str.len()\n",
    "df_combo_005_with_len.loc[df_combo_005_with_len['Syllables'] == 0, 'Syllables'] = df_combo_005_with_len['TermLen']\n",
    "\n",
    "bins = [0,1,2,4,8,128]\n",
    "labels = [\"[1]\",\"[2]\",\"[3:4]\",\"[5:8]\",\"[9: ]\"]\n",
    "# https://stackoverflow.com/questions/45273731/binning-column-with-python-pandas\n",
    "df_combo_005_with_len['TermLenGroup'] = pd.cut(df_combo_005_with_len['TermLen'], bins=bins, labels=labels)\n",
    "\n",
    "#df.loc[df['Grades'] <= 77, 'Grades'] = 100\n",
    "# https://stackoverflow.com/questions/42815768/pandas-adding-column-with-the-length-of-other-column-as-value\n",
    "#df_binary2.head(35)[30:]\n",
    "df_combo_005_with_len.tail(20)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. Inspect the longest syllable entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>Translation</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>due</th>\n",
       "      <th>...</th>\n",
       "      <th>hasVisual</th>\n",
       "      <th>hasAudio</th>\n",
       "      <th>hasMultiMeaning</th>\n",
       "      <th>hasMultiReading</th>\n",
       "      <th>hasSimilar</th>\n",
       "      <th>hasHomophone</th>\n",
       "      <th>hasAltForm</th>\n",
       "      <th>TermLen</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>TermLenGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1346057958628</td>\n",
       "      <td>inspect fromdict fromnewspaper history culture</td>\n",
       "      <td>東京電力福島・第１原発事故</td>\n",
       "      <td>とうきょうでんりょくふくしま・だいいちげんぱつじこ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-08-27</td>\n",
       "      <td>1346057958628</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1346215143756</td>\n",
       "      <td>fromdict datesandtime numeric</td>\n",
       "      <td>1837～1901年</td>\n",
       "      <td>せんはっぴゃくさんじゅうななねんからせんきゅうひゃくいちねん</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>1346215143756</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1346216471844</td>\n",
       "      <td>counter datesandtime fromdict numeric</td>\n",
       "      <td>千九百八十九年</td>\n",
       "      <td>せんきゅうひゃくはちじゅうきゅうねん</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>1346216471844</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1346220179889</td>\n",
       "      <td>counter datesandtime fromdict numeric</td>\n",
       "      <td>千九百四十五年</td>\n",
       "      <td>せんきゅうひゃくよんじゅうごねん</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>1346220179889</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1346220179894</td>\n",
       "      <td>fromdict fromnewspaper</td>\n",
       "      <td>国連安全保障理事会</td>\n",
       "      <td>こくれんあんぜんほしょうりじかい</td>\n",
       "      <td>United Nations Security Board of Directors</td>\n",
       "      <td></td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>1346220179894</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1346220179894</td>\n",
       "      <td>fromdict fromnewspaper</td>\n",
       "      <td>国連安全保障理事会</td>\n",
       "      <td>こくれんあんぜんほしょうりじかい</td>\n",
       "      <td>United Nations Security Board of Directors</td>\n",
       "      <td></td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>1379660811751</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>1354972584071</td>\n",
       "      <td>fromdict katakana technical</td>\n",
       "      <td>オブジェクト指向プログラミング</td>\n",
       "      <td>オブジェクトしこうプログラミング</td>\n",
       "      <td>object-oriented programming</td>\n",
       "      <td>Noun, Computer terminology</td>\n",
       "      <td>2012-12-08</td>\n",
       "      <td>1354972584071</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>1387411183585</td>\n",
       "      <td>numeric datesandtime</td>\n",
       "      <td>千九百八十七年</td>\n",
       "      <td>せんきゅうひゃくはちじゅうななねん</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>1387411238321</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>[5:8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>1411020895026</td>\n",
       "      <td>math technical</td>\n",
       "      <td>二次方程式の解の公式</td>\n",
       "      <td>にじほうていしきのかいのこうしき</td>\n",
       "      <td>the quadratic formula</td>\n",
       "      <td>Noun, technical, math</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>1411021140081</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>[9: ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid                                            tags  \\\n",
       "234   1346057958628  inspect fromdict fromnewspaper history culture   \n",
       "301   1346215143756                   fromdict datesandtime numeric   \n",
       "414   1346216471844           counter datesandtime fromdict numeric   \n",
       "434   1346220179889           counter datesandtime fromdict numeric   \n",
       "439   1346220179894                          fromdict fromnewspaper   \n",
       "440   1346220179894                          fromdict fromnewspaper   \n",
       "3048  1354972584071                     fromdict katakana technical   \n",
       "5743  1387411183585                            numeric datesandtime   \n",
       "7535  1411020895026                                  math technical   \n",
       "\n",
       "                 Term                           Yomi1  \\\n",
       "234     東京電力福島・第１原発事故       とうきょうでんりょくふくしま・だいいちげんぱつじこ   \n",
       "301        1837～1901年  せんはっぴゃくさんじゅうななねんからせんきゅうひゃくいちねん   \n",
       "414           千九百八十九年              せんきゅうひゃくはちじゅうきゅうねん   \n",
       "434           千九百四十五年                せんきゅうひゃくよんじゅうごねん   \n",
       "439         国連安全保障理事会                こくれんあんぜんほしょうりじかい   \n",
       "440         国連安全保障理事会                こくれんあんぜんほしょうりじかい   \n",
       "3048  オブジェクト指向プログラミング                オブジェクトしこうプログラミング   \n",
       "5743          千九百八十七年               せんきゅうひゃくはちじゅうななねん   \n",
       "7535       二次方程式の解の公式                にじほうていしきのかいのこうしき   \n",
       "\n",
       "                                     Translation                PartOfSpeech  \\\n",
       "234                                                                            \n",
       "301                                                                            \n",
       "414                                                                            \n",
       "434                                                                            \n",
       "439   United Nations Security Board of Directors                               \n",
       "440   United Nations Security Board of Directors                               \n",
       "3048                 object-oriented programming  Noun, Computer terminology   \n",
       "5743                                                                           \n",
       "7535                       the quadratic formula       Noun, technical, math   \n",
       "\n",
       "     NoteCreated             id  ord         due      ...       hasVisual  \\\n",
       "234   2012-08-27  1346057958628    0  2015-07-07      ...               0   \n",
       "301   2012-08-29  1346215143756    0  2015-07-14      ...               0   \n",
       "414   2012-08-29  1346216471844    0  2015-11-24      ...               0   \n",
       "434   2012-08-29  1346220179889    0  2016-01-20      ...               0   \n",
       "439   2012-08-29  1346220179894    0  2015-05-08      ...               1   \n",
       "440   2012-08-29  1379660811751    4  2018-05-21      ...               1   \n",
       "3048  2012-12-08  1354972584071    0  2015-07-09      ...               0   \n",
       "5743  2013-12-18  1387411238321    0  2015-11-26      ...               0   \n",
       "7535  2014-09-18  1411021140081    0  2015-08-07      ...               1   \n",
       "\n",
       "      hasAudio  hasMultiMeaning  hasMultiReading hasSimilar hasHomophone  \\\n",
       "234          0                0                0          0            0   \n",
       "301          0                0                0          0            0   \n",
       "414          0                0                0          0            0   \n",
       "434          0                0                0          0            0   \n",
       "439          1                0                0          0            0   \n",
       "440          1                0                0          0            0   \n",
       "3048         0                0                0          0            0   \n",
       "5743         0                0                0          0            0   \n",
       "7535         0                0                0          0            0   \n",
       "\n",
       "      hasAltForm  TermLen  Syllables  TermLenGroup  \n",
       "234            0       13         25         [9: ]  \n",
       "301            0       10         30         [9: ]  \n",
       "414            0        7         18         [5:8]  \n",
       "434            0        7         16         [5:8]  \n",
       "439            0        9         16         [9: ]  \n",
       "440            0        9         16         [9: ]  \n",
       "3048           0       15         16         [9: ]  \n",
       "5743           0        7         17         [5:8]  \n",
       "7535           0       10         16         [9: ]  \n",
       "\n",
       "[9 rows x 48 columns]"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_many_syl = df_combo_005_with_len.copy()\n",
    "many_syl = df_many_syl['Syllables'] > 15\n",
    "df_many_syl.loc[many_syl] #todo: check nid of 1391477462767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nid', 'tags', 'Term', 'Yomi1', 'Translation', 'PartOfSpeech',\n",
       "       'NoteCreated', 'id', 'ord', 'due', 'ivl', 'factor', 'reps',\n",
       "       'lapses', 'CardCreated', 'CardType', 'commonword', 'clothing',\n",
       "       'animal', 'body', 'food', 'place', 'textbook', 'college',\n",
       "       'fromdict', 'fromexam', 'len1', 'n1', 'n2', 'n3', 'n4', 'n5',\n",
       "       'katakana', 'hiragana', 'noun', 'verb', 'convo', 'ivl_q',\n",
       "       'hasVisual', 'hasAudio', 'hasMultiMeaning', 'hasMultiReading',\n",
       "       'hasSimilar', 'hasHomophone', 'hasAltForm', 'TermLen', 'Syllables',\n",
       "       'TermLenGroup'], dtype=object)"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_005_with_len.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. Remove unneeded Translation & PartOfSpeech columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_006_less_cols = df_combo_005_with_len.copy()\n",
    "df_combo_006_less_cols = df_combo_006_less_cols.drop(['Translation','PartOfSpeech'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels terms by their jlpt level.\n",
    "# bear in mind that some terms have multiple jlpt levels.\n",
    "# this function merely assigns the lowest associated jlpt level with a term. \n",
    "def label_jlpt_lvl (row):\n",
    "    if row['n5'] == 1 :\n",
    "        return 5\n",
    "    elif row['n4'] == 1:\n",
    "        return 4\n",
    "    elif row['n3'] == 1:\n",
    "        return 3\n",
    "    elif row['n2'] == 1:\n",
    "        return 2\n",
    "    elif row['n1'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. Assign JLPT number to words with JLPT \"N\" levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_007_jptl_lvl = df_combo_006_less_cols.copy()\n",
    "df_combo_007_jptl_lvl['jlpt_lvl'] = df_combo_007_jptl_lvl.apply (lambda row: label_jlpt_lvl(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nid', 'tags', 'Term', 'Yomi1', 'NoteCreated', 'id', 'ord', 'due',\n",
       "       'ivl', 'factor', 'reps', 'lapses', 'CardCreated', 'CardType',\n",
       "       'commonword', 'clothing', 'animal', 'body', 'food', 'place',\n",
       "       'textbook', 'college', 'fromdict', 'fromexam', 'len1', 'n1', 'n2',\n",
       "       'n3', 'n4', 'n5', 'katakana', 'hiragana', 'noun', 'verb', 'convo',\n",
       "       'ivl_q', 'hasVisual', 'hasAudio', 'hasMultiMeaning',\n",
       "       'hasMultiReading', 'hasSimilar', 'hasHomophone', 'hasAltForm',\n",
       "       'TermLen', 'Syllables', 'TermLenGroup', 'jlpt_lvl'], dtype=object)"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_007_jptl_lvl.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    176\n",
       "5.0    147\n",
       "4.0    100\n",
       "2.0     31\n",
       "1.0     22\n",
       "Name: jlpt_lvl, dtype: int64"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_007_jptl_lvl['jlpt_lvl'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45. Create dummy variables for card type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_008_dummies = df_combo_007_jptl_lvl.copy()\n",
    "\n",
    "df_combo_008_dummies = pd.get_dummies(df_combo_008_dummies, columns=['CardType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>tags</th>\n",
       "      <th>Term</th>\n",
       "      <th>Yomi1</th>\n",
       "      <th>NoteCreated</th>\n",
       "      <th>id</th>\n",
       "      <th>ord</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>...</th>\n",
       "      <th>hasHomophone</th>\n",
       "      <th>hasAltForm</th>\n",
       "      <th>TermLen</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>TermLenGroup</th>\n",
       "      <th>jlpt_lvl</th>\n",
       "      <th>CardType_listen</th>\n",
       "      <th>CardType_look</th>\n",
       "      <th>CardType_read</th>\n",
       "      <th>CardType_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7947</th>\n",
       "      <td>1523892839900</td>\n",
       "      <td>commonword noun n5</td>\n",
       "      <td>万年筆</td>\n",
       "      <td>まんねんひつ</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>1523893083493</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>27</td>\n",
       "      <td>2210</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[3:4]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7948</th>\n",
       "      <td>1523892839900</td>\n",
       "      <td>commonword noun n5</td>\n",
       "      <td>万年筆</td>\n",
       "      <td>まんねんひつ</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>1523893083509</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>515</td>\n",
       "      <td>2410</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[3:4]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949</th>\n",
       "      <td>1523892839900</td>\n",
       "      <td>commonword noun n5</td>\n",
       "      <td>万年筆</td>\n",
       "      <td>まんねんひつ</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>1523893129423</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>13</td>\n",
       "      <td>2210</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[3:4]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>1523892839900</td>\n",
       "      <td>commonword noun n5</td>\n",
       "      <td>万年筆</td>\n",
       "      <td>まんねんひつ</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>1524841320859</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>4</td>\n",
       "      <td>2050</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[3:4]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7951</th>\n",
       "      <td>1549184119039</td>\n",
       "      <td></td>\n",
       "      <td>閏年</td>\n",
       "      <td>うるうどし</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>1549184129288</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>108</td>\n",
       "      <td>2410</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nid                tags Term   Yomi1 NoteCreated  \\\n",
       "7947  1523892839900  commonword noun n5  万年筆  まんねんひつ  2018-04-16   \n",
       "7948  1523892839900  commonword noun n5  万年筆  まんねんひつ  2018-04-16   \n",
       "7949  1523892839900  commonword noun n5  万年筆  まんねんひつ  2018-04-16   \n",
       "7950  1523892839900  commonword noun n5  万年筆  まんねんひつ  2018-04-16   \n",
       "7951  1549184119039                       閏年   うるうどし  2019-02-03   \n",
       "\n",
       "                 id  ord         due  ivl  factor       ...         \\\n",
       "7947  1523893083493    0  2018-06-14   27    2210       ...          \n",
       "7948  1523893083509    7  2020-10-01  515    2410       ...          \n",
       "7949  1523893129423    2  2018-06-14   13    2210       ...          \n",
       "7950  1524841320859    4  2019-05-05    4    2050       ...          \n",
       "7951  1549184129288    0  2019-08-21  108    2410       ...          \n",
       "\n",
       "      hasHomophone  hasAltForm TermLen  Syllables  TermLenGroup  jlpt_lvl  \\\n",
       "7947             0           0       3          6         [3:4]       5.0   \n",
       "7948             0           0       3          6         [3:4]       5.0   \n",
       "7949             0           0       3          6         [3:4]       5.0   \n",
       "7950             0           0       3          6         [3:4]       5.0   \n",
       "7951             0           0       2          5           [2]       NaN   \n",
       "\n",
       "      CardType_listen  CardType_look  CardType_read  CardType_recall  \n",
       "7947                0              0              1                0  \n",
       "7948                1              0              0                0  \n",
       "7949                0              0              0                1  \n",
       "7950                0              1              0                0  \n",
       "7951                0              0              1                0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_008_dummies.tail(10)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46. Group notes by ID to determine card type overlap, simple totals per note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/23919563/merge-rows-of-a-dataframe-in-pandas-based-on-a-column\n",
    "df_combo_009_grouped_notes = df_combo_008_dummies.groupby(['nid']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>katakana</th>\n",
       "      <th>hiragana</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>convo</th>\n",
       "      <th>CardType_listen</th>\n",
       "      <th>CardType_look</th>\n",
       "      <th>CardType_read</th>\n",
       "      <th>CardType_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1508012628565</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523892839900</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549184119039</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550402953788</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550403040864</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               reps  lapses  katakana  hiragana  noun  verb  convo  \\\n",
       "nid                                                                  \n",
       "1508012628565    10       1         0         0     0     0      0   \n",
       "1523892839900    31       4         0         0     4     0      0   \n",
       "1549184119039     8       0         0         0     0     0      0   \n",
       "1550402953788    12       2         0         0     2     0      2   \n",
       "1550403040864     7       0         0         0     0     0      0   \n",
       "\n",
       "               CardType_listen  CardType_look  CardType_read  CardType_recall  \n",
       "nid                                                                            \n",
       "1508012628565                1              1              1                1  \n",
       "1523892839900                1              1              1                1  \n",
       "1549184119039                0              0              1                1  \n",
       "1550402953788                0              0              1                1  \n",
       "1550403040864                0              0              1                1  "
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this data frame will provide total reps per term, total lapses per term, and vectors (card types) per term \n",
    "df_combo_009_grouped_notes.tail(20)[-5:]\n",
    "\n",
    "df_notes_008_totals = df_combo_009_grouped_notes.copy()\n",
    "df_notes_008_totals = df_notes_008_totals.drop(['id','ivl','ord','factor','commonword','clothing','animal',\n",
    "    'body','food','place','textbook','college','fromdict','fromexam','len1','n1','n2','n3','n4','n5',\n",
    "    'ivl_q','hasVisual','hasAudio','hasMultiMeaning','hasMultiReading','hasSimilar','hasHomophone',\n",
    "    'hasAltForm','TermLen','Syllables','jlpt_lvl'],axis=1)\n",
    "df_notes_008_totals.tail(20)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_008_totals = df_notes_008_totals.rename(columns={'reps':'reps_total','lapses':'lapses_total',\n",
    "    'CardType_listen':'hasListenCard', 'CardType_recall':'hasTranslateCard',\n",
    "    'CardType_read':'hasReadCard', 'CardType_look':'hasPictureCard'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reps_total</th>\n",
       "      <th>lapses_total</th>\n",
       "      <th>katakana</th>\n",
       "      <th>hiragana</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>convo</th>\n",
       "      <th>hasListenCard</th>\n",
       "      <th>hasPictureCard</th>\n",
       "      <th>hasReadCard</th>\n",
       "      <th>hasTranslateCard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1508012628565</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523892839900</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549184119039</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550402953788</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550403040864</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               reps_total  lapses_total  katakana  hiragana  noun  verb  \\\n",
       "nid                                                                       \n",
       "1508012628565          10             1         0         0     0     0   \n",
       "1523892839900          31             4         0         0     4     0   \n",
       "1549184119039           8             0         0         0     0     0   \n",
       "1550402953788          12             2         0         0     2     0   \n",
       "1550403040864           7             0         0         0     0     0   \n",
       "\n",
       "               convo  hasListenCard  hasPictureCard  hasReadCard  \\\n",
       "nid                                                                \n",
       "1508012628565      0              1               1            1   \n",
       "1523892839900      0              1               1            1   \n",
       "1549184119039      0              0               0            1   \n",
       "1550402953788      2              0               0            1   \n",
       "1550403040864      0              0               0            1   \n",
       "\n",
       "               hasTranslateCard  \n",
       "nid                              \n",
       "1508012628565                 1  \n",
       "1523892839900                 1  \n",
       "1549184119039                 1  \n",
       "1550402953788                 1  \n",
       "1550403040864                 1  "
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_008_totals.tail(20)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47. Group notes by ID to find simple average means per note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_009_means = df_combo_008_dummies.copy()\n",
    "df_notes_009_means = df_notes_009_means.groupby(['nid']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_ivl</th>\n",
       "      <th>mean_factor</th>\n",
       "      <th>mean_reps</th>\n",
       "      <th>mean_lapses</th>\n",
       "      <th>katakana</th>\n",
       "      <th>hiragana</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>convo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1508012628565</th>\n",
       "      <td>130.50</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523892839900</th>\n",
       "      <td>139.75</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549184119039</th>\n",
       "      <td>97.50</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550402953788</th>\n",
       "      <td>5.00</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550403040864</th>\n",
       "      <td>87.50</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_ivl  mean_factor  mean_reps  mean_lapses  katakana  \\\n",
       "nid                                                                      \n",
       "1508012628565    130.50       2360.0       2.50         0.25       0.0   \n",
       "1523892839900    139.75       2220.0       7.75         1.00       0.0   \n",
       "1549184119039     97.50       2410.0       4.00         0.00       0.0   \n",
       "1550402953788      5.00       2210.0       6.00         1.00       0.0   \n",
       "1550403040864     87.50       2410.0       3.50         0.00       0.0   \n",
       "\n",
       "               hiragana  noun  verb  convo  \n",
       "nid                                         \n",
       "1508012628565       0.0   0.0   0.0    0.0  \n",
       "1523892839900       0.0   1.0   0.0    0.0  \n",
       "1549184119039       0.0   0.0   0.0    0.0  \n",
       "1550402953788       0.0   1.0   0.0    1.0  \n",
       "1550403040864       0.0   0.0   0.0    0.0  "
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_009_means = df_notes_009_means.drop(['id','ord','commonword','clothing','animal','body',\n",
    "    'food','place','textbook','college','fromdict','fromexam','len1','n1','n2','n3','n4','n5','ivl_q',\n",
    "    'hasVisual','hasAudio','hasMultiMeaning','hasMultiReading','hasSimilar','hasHomophone','hasAltForm',\n",
    "    'TermLen','Syllables','jlpt_lvl','CardType_listen','CardType_recall',\n",
    "    'CardType_read','CardType_look'],axis=1)\n",
    "df_notes_009_means = df_notes_009_means.rename(columns={'ivl':'mean_ivl','factor':'mean_factor',\n",
    "                                                        'reps':'mean_reps','lapses':'mean_lapses'})\n",
    "df_notes_009_means.tail(20)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 48. Combine note totals, note means & general notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_ivl</th>\n",
       "      <th>mean_factor</th>\n",
       "      <th>mean_reps</th>\n",
       "      <th>mean_lapses</th>\n",
       "      <th>katakana_x</th>\n",
       "      <th>hiragana_x</th>\n",
       "      <th>noun_x</th>\n",
       "      <th>verb_x</th>\n",
       "      <th>convo_x</th>\n",
       "      <th>reps_total</th>\n",
       "      <th>lapses_total</th>\n",
       "      <th>katakana_y</th>\n",
       "      <th>hiragana_y</th>\n",
       "      <th>noun_y</th>\n",
       "      <th>verb_y</th>\n",
       "      <th>convo_y</th>\n",
       "      <th>hasListenCard</th>\n",
       "      <th>hasPictureCard</th>\n",
       "      <th>hasReadCard</th>\n",
       "      <th>hasTranslateCard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1331799797112</th>\n",
       "      <td>149.0</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331799797114</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331799797117</th>\n",
       "      <td>143.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331799797118</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331799797121</th>\n",
       "      <td>132.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_ivl  mean_factor  mean_reps  mean_lapses  katakana_x  \\\n",
       "nid                                                                        \n",
       "1331799797112     149.0       2080.0        8.0          1.0         0.0   \n",
       "1331799797114      99.0       1980.0        7.0          0.0         0.0   \n",
       "1331799797117     143.0       2130.0        6.0          1.0         0.0   \n",
       "1331799797118      74.0       1880.0       15.0          3.0         0.0   \n",
       "1331799797121     132.0       2130.0        6.0          1.0         0.0   \n",
       "\n",
       "               hiragana_x  noun_x  verb_x  convo_x  reps_total  lapses_total  \\\n",
       "nid                                                                            \n",
       "1331799797112         0.0     0.0     0.0      0.0           8             1   \n",
       "1331799797114         0.0     0.0     0.0      0.0           7             0   \n",
       "1331799797117         0.0     0.0     1.0      0.0           6             1   \n",
       "1331799797118         0.0     0.0     0.0      1.0          15             3   \n",
       "1331799797121         0.0     0.0     0.0      0.0           6             1   \n",
       "\n",
       "               katakana_y  hiragana_y  noun_y  verb_y  convo_y  hasListenCard  \\\n",
       "nid                                                                             \n",
       "1331799797112           0           0       0       0        0              0   \n",
       "1331799797114           0           0       0       0        0              0   \n",
       "1331799797117           0           0       0       1        0              0   \n",
       "1331799797118           0           0       0       0        1              0   \n",
       "1331799797121           0           0       0       0        0              0   \n",
       "\n",
       "               hasPictureCard  hasReadCard  hasTranslateCard  \n",
       "nid                                                           \n",
       "1331799797112               0            1                 0  \n",
       "1331799797114               0            1                 0  \n",
       "1331799797117               0            1                 0  \n",
       "1331799797118               0            1                 0  \n",
       "1331799797121               0            1                 0  "
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_010_combo = df_notes_009_means.copy()\n",
    "df_notes_010_combo = pd.merge(df_notes_010_combo, df_notes_008_totals,on='nid')\n",
    "df_notes_010_combo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import in Review Log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revlog = pd.read_sql_query(\"SELECT * FROM revlog\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114129, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cid</th>\n",
       "      <th>usn</th>\n",
       "      <th>ease</th>\n",
       "      <th>ivl</th>\n",
       "      <th>lastIvl</th>\n",
       "      <th>factor</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1332393018515</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>6673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1333279992123</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>11656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1333280001016</td>\n",
       "      <td>1331799797112</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>8887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1333280097922</td>\n",
       "      <td>1331799797113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>29162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1333280107916</td>\n",
       "      <td>1331799797114</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>9987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id            cid  usn  ease  ivl  lastIvl  factor   time  type\n",
       "0  1332393018515  1331799797110    0     1    0        0    2500   6673     0\n",
       "1  1333279992123  1331799797110    0     4    8        0    2600  11656     0\n",
       "2  1333280001016  1331799797112    0     4    8        0    2600   8887     0\n",
       "3  1333280097922  1331799797113    0     1    0        0    2500  29162     0\n",
       "4  1333280107916  1331799797114    0     4    8        0    2600   9987     0"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_revlog.shape)\n",
    "df_revlog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_card_by_id(df_in, id_num, id_name):\n",
    "    return df_in[df_in[id_name]==id_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revlog_001_review_date = df_revlog.copy()\n",
    "df_revlog_001_review_date = df_revlog_001_review_date.rename(columns={'id':'rid'})\n",
    "df_revlog_001_review_date['ReviewDate']= pd.to_datetime(df_revlog_001_review_date['rid'],unit='ms')\n",
    "df_revlog_001_review_date['ReviewDate'] = df_revlog_001_review_date['ReviewDate'].dt.date\n",
    "df_revlog_001_review_date.head()\n",
    "\n",
    "assertEquals(df_revlog_001_review_date['rid'].iloc[0], 1332393018515, \"Note ID is in Epoch Units\")\n",
    "assertEquals(str(df_revlog_001_review_date['ReviewDate'].iloc[0]), \"2012-03-22\", \"Note ID is in datetime date format year-month-day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1331799797110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nid</th>\n",
       "      <th>ord</th>\n",
       "      <th>queue</th>\n",
       "      <th>due</th>\n",
       "      <th>ivl</th>\n",
       "      <th>factor</th>\n",
       "      <th>reps</th>\n",
       "      <th>lapses</th>\n",
       "      <th>CardCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1331799797110</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-08</td>\n",
       "      <td>65</td>\n",
       "      <td>1680</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id            nid  ord  queue         due  ivl  factor  reps  \\\n",
       "0  1331799797110  1331799797110    0      2  2015-03-08   65    1680    10   \n",
       "\n",
       "   lapses CardCreated  \n",
       "0       1  2012-03-15  "
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_note_id = inspect_card_by_id(df_cards_final, df_revlog['cid'].iloc[0], 'id')['nid'].iloc[0]\n",
    "\n",
    "print(current_note_id)\n",
    "\n",
    "#print(\"Note ID: \", inspect_note_by_id(df_notes_final_001,current_note_id)['nid'].iloc[0])\n",
    "#print(\"Term: \", inspect_note_by_id(df_notes_final_001,current_note_id)['Term'].iloc[0])\n",
    "#print(\"Translation: \", inspect_note_by_id(df_notes_final_001,current_note_id)['Translation'].iloc[0])\n",
    "\n",
    "inspect_card_by_id(df_cards_final, df_revlog['cid'].iloc[0], 'id') # in df_cards_final (X) look for a card of 'card id' X in the column name 'id' Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>cid</th>\n",
       "      <th>usn</th>\n",
       "      <th>ease</th>\n",
       "      <th>ivl</th>\n",
       "      <th>lastIvl</th>\n",
       "      <th>factor</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>ReviewDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1332393018515</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>6673</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1333279992123</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>11656</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80368</th>\n",
       "      <td>1397571358201</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>4480</td>\n",
       "      <td>1</td>\n",
       "      <td>-60</td>\n",
       "      <td>-60</td>\n",
       "      <td>2500</td>\n",
       "      <td>4292</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80369</th>\n",
       "      <td>1397571360841</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>4480</td>\n",
       "      <td>2</td>\n",
       "      <td>-600</td>\n",
       "      <td>-60</td>\n",
       "      <td>2500</td>\n",
       "      <td>2636</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80370</th>\n",
       "      <td>1397571363081</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>4480</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-600</td>\n",
       "      <td>2280</td>\n",
       "      <td>2238</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80377</th>\n",
       "      <td>1397622541113</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>4490</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2280</td>\n",
       "      <td>4023</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83544</th>\n",
       "      <td>1400914850867</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>4958</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2130</td>\n",
       "      <td>3323</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93052</th>\n",
       "      <td>1410177777778</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>6257</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>1980</td>\n",
       "      <td>2300</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98902</th>\n",
       "      <td>1414062295845</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>6748</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>1830</td>\n",
       "      <td>16176</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104064</th>\n",
       "      <td>1420285596480</td>\n",
       "      <td>1331799797110</td>\n",
       "      <td>7154</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>1680</td>\n",
       "      <td>11880</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rid            cid   usn  ease  ivl  lastIvl  factor   time  \\\n",
       "0       1332393018515  1331799797110     0     1    0        0    2500   6673   \n",
       "1       1333279992123  1331799797110     0     4    8        0    2600  11656   \n",
       "80368   1397571358201  1331799797110  4480     1  -60      -60    2500   4292   \n",
       "80369   1397571360841  1331799797110  4480     2 -600      -60    2500   2636   \n",
       "80370   1397571363081  1331799797110  4480     2    1     -600    2280   2238   \n",
       "80377   1397622541113  1331799797110  4490     3    2        1    2280   4023   \n",
       "83544   1400914850867  1331799797110  4958     2   12        2    2130   3323   \n",
       "93052   1410177777778  1331799797110  6257     2   44       12    1980   2300   \n",
       "98902   1414062295845  1331799797110  6748     2   51       44    1830  16176   \n",
       "104064  1420285596480  1331799797110  7154     2   65       51    1680  11880   \n",
       "\n",
       "        type  ReviewDate  \n",
       "0          0  2012-03-22  \n",
       "1          0  2012-04-01  \n",
       "80368      0  2014-04-15  \n",
       "80369      0  2014-04-15  \n",
       "80370      0  2014-04-15  \n",
       "80377      1  2014-04-16  \n",
       "83544      1  2014-05-24  \n",
       "93052      1  2014-09-08  \n",
       "98902      1  2014-10-23  \n",
       "104064     1  2015-01-03  "
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect_card_by_id(df_revlog_001_review_date, df_revlog['cid'].iloc[0], 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
